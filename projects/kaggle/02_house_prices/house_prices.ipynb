{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2bdd172",
   "metadata": {},
   "source": [
    "# House Prices - Advanced Regression Techniques\n",
    "*Predict sales prices and practice feature engineering, RFs, and gradient boosting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2336,
   "id": "1298fd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: apply all this transformations for train & test datasets, and then split again\n",
    "# TODO: make boxcox run! (maybe just for a few ft.?)\n",
    "# TODO: use other regression models\n",
    "# TODO: try with AmesHousing.csv!!!\n",
    "# TODO: reduce overfitting on GradientBoostingRegressor (after testing with leaked file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2337,
   "id": "1b8fd1e7-2a7f-48ea-9bf0-2e4aa8d36cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum\n",
    "\n",
    "# Set the aesthetics for the plots\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "RANDOM_STATE = 101\n",
    "\n",
    "\n",
    "class ScalerType(Enum):\n",
    "    STANDARD = \"standard\"\n",
    "    ROBUST = \"robust\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822bbff9",
   "metadata": {},
   "source": [
    "### Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2338,
   "id": "4dffafdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "0            Lvl    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "1            Lvl    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "1458         Lvl    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "1459         Lvl    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008        WD         Normal     208500  \n",
       "1         5   2007        WD         Normal     181500  \n",
       "1458      4   2010        WD         Normal     142125  \n",
       "1459      6   2008        WD         Normal     147500  \n",
       "\n",
       "[4 rows x 81 columns]"
      ]
     },
     "execution_count": 2338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./data/train.csv\")\n",
    "pd.concat([df_train.head(2), df_train.tail(2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5885f975",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2339,
   "id": "710ba6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 2339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2340,
   "id": "f177a227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              # missing  % missing\n",
      "PoolQC             1453      99.52\n",
      "MiscFeature        1406      96.30\n",
      "Alley              1369      93.77\n",
      "Fence              1179      80.75\n",
      "MasVnrType          872      59.73\n",
      "FireplaceQu         690      47.26\n",
      "LotFrontage         259      17.74\n",
      "GarageYrBlt          81       5.55\n",
      "GarageCond           81       5.55\n",
      "GarageType           81       5.55\n",
      "GarageFinish         81       5.55\n",
      "GarageQual           81       5.55\n",
      "BsmtFinType2         38       2.60\n",
      "BsmtExposure         38       2.60\n",
      "BsmtQual             37       2.53\n",
      "BsmtCond             37       2.53\n",
      "BsmtFinType1         37       2.53\n",
      "MasVnrArea            8       0.55\n",
      "Electrical            1       0.07\n"
     ]
    }
   ],
   "source": [
    "def show_missing_data(df):\n",
    "    \"\"\"\n",
    "    Display number and percentage of columns with any missing value\n",
    "    \"\"\"\n",
    "    total = df.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (\n",
    "        ((df.isnull().sum() / df.isnull().count()) * 100)\n",
    "        .sort_values(ascending=False)\n",
    "        .round(2)\n",
    "    )\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=[\"# missing\", \"% missing\"])\n",
    "    print(missing_data[missing_data[\"# missing\"] > 0])\n",
    "\n",
    "\n",
    "show_missing_data(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ac66bc",
   "metadata": {},
   "source": [
    "- `PoolQC`=NA means no pool\n",
    "- `MiscFeature`=NA means there are no extra features (e.g.: Elevator, Tennis Court..)\n",
    "- `Alley`=NA means no alley access\n",
    "- `Fence`=NA means no fence\n",
    "- `MasVnrType`=NA means None\n",
    "- `FireplaceQu`=NA means no Fireplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2341,
   "id": "aac86309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.displot(df_train[\"SalePrice\"] / 100000, bins=40, kde=True, height=3, aspect=2)\n",
    "plt.xticks(ticks=[i for i in range(0, 8)], labels=[f\"{i}00K\" for i in range(0, 8)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97787a5",
   "metadata": {},
   "source": [
    "ℹ️ Careful -> skewed distribution of price\n",
    "\n",
    "- In statistical analysis, a non-skewed distribution is typically a normal distribution, which resembles a bell curve when graphed. This means it's symmetric, with most of the observations clustering around the central peak and the probabilities for values further away from the mean tapering off equally in both directions.\n",
    "\n",
    "- If we don't apply a log transformation to SalePrice when it's skewed, our model may not perform as well, especially if it assumes that the residuals (errors) are normally distributed, as many linear models do. Applying a log transformation can help stabilize the variance across the data range and make the data conform more closely to the assumptions of parametric statistical tests, leading to more reliable statistical inference and potentially better model performance. If a log transformation is applied, the distribution should look more like a normal distribution, with fewer outliers and a more symmetric shape.\n",
    "\n",
    "- When should log **NOT** be applied to the target variable?\n",
    "  - The distribution of the target variable is already close to normal. Log transformation in such cases might lead to a worse fit.\n",
    "  - The model you're using is robust to non-normality, like tree-based models (e.g., decision trees, random forests).\n",
    "  - The range of the target variable is narrow with low variance, so the proportional differences are minimal.\n",
    "  - You have a binary or categorical target variable. In classification problems, log transformation is not applicable.\n",
    "  - The relationship between predictors and the target is linear, and there are no signs of heteroscedasticity (uneven spread of residuals)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a58f0ec",
   "metadata": {},
   "source": [
    "### Data cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2419,
   "id": "bf8059dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nulls(df):\n",
    "    # convert numerical (but actually categorical) features to str\n",
    "    df[[\"MSSubClass\", \"YrSold\", \"MoSold\"]] = df[\n",
    "        [\"MSSubClass\", \"YrSold\", \"MoSold\"]\n",
    "    ].astype(str)\n",
    "\n",
    "    # fill NA with default values\n",
    "    df[\"Fence\"] = df[\"Fence\"].fillna(\"NoFence\")\n",
    "    df[\"Alley\"] = df[\"Alley\"].fillna(\"NoAlleyAccess\")\n",
    "    df[\"MiscFeature\"] = df[\"MiscFeature\"].fillna(\"None\")\n",
    "    df[\"MasVnrType\"] = df[\"MasVnrType\"].fillna(\"None\")\n",
    "    df[\"FireplaceQu\"] = df[\"FireplaceQu\"].fillna(\"NoFireplace\")\n",
    "\n",
    "    # fill NA with 0\n",
    "    for col in (\n",
    "        \"MasVnrArea\",\n",
    "        \"TotalBsmtSF\",\n",
    "        \"BsmtUnfSF\",\n",
    "        \"BsmtFullBath\",\n",
    "        \"BsmtHalfBath\",\n",
    "        \"BsmtFinSF1\",\n",
    "        \"BsmtFinSF2\",\n",
    "        \"GarageCars\",\n",
    "        \"GarageArea\",\n",
    "    ):\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "    # fill NA for basement\n",
    "    for col in (\"BsmtQual\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\"):\n",
    "        df[col] = df[col].fillna(\"None\")\n",
    "\n",
    "    # fill NA for garage\n",
    "    df[\"GarageYrBlt\"] = df[\"GarageYrBlt\"].fillna(df[\"YearBuilt\"])\n",
    "    garage_columns = [\"GarageType\", \"GarageFinish\", \"GarageQual\", \"GarageCond\"]\n",
    "    df[garage_columns] = df[garage_columns].fillna(\"NoGarage\")\n",
    "\n",
    "    # fill NA based on mode/median\n",
    "    # (Mean is sensitive to outliers, whereas median is more robust)\n",
    "    df[\"Electrical\"] = df[\"Electrical\"].fillna(df[\"Electrical\"].mode()[0])  # 'SBrkr'\n",
    "    df[\"Functional\"] = df[\"Functional\"].fillna(df[\"Functional\"].mode()[0])  # 'Typ'\n",
    "    df[\"KitchenQual\"] = df[\"KitchenQual\"].fillna(df[\"KitchenQual\"].mode()[0])  # 'TA'\n",
    "    df[\"SaleType\"] = df[\"SaleType\"].fillna(df[\"SaleType\"].mode()[0])  # 'WD'\n",
    "    df[\"MSZoning\"] = df.groupby(\"MSSubClass\")[\"MSZoning\"].transform(\n",
    "        lambda x: x.fillna(x.mode()[0])\n",
    "    )\n",
    "\n",
    "    # df[\"LotFrontage\"] = df.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "    #     lambda x: x.fillna(x.median())\n",
    "    # )\n",
    "\n",
    "    # assign median to Neighborhoods Without LotFrontage data\n",
    "    lot_frontage_median = df[\"LotFrontage\"].median()\n",
    "    df.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "        lambda x: x.fillna(x.median() if not x.isna().all() else lot_frontage_median)\n",
    "    )\n",
    "\n",
    "    # remove outliers (no clue why, but worth investigating..)\n",
    "    df = df.drop(index=[30, 88, 462, 631, 1322, 523, 691, 1182, 1298])\n",
    "    df = df[df.GrLivArea < 4500].reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d291f9b2",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2343,
   "id": "a132f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding binary vars (are often easier to interpret for models than continuous ft.)\n",
    "# E.g. hypothesis:\n",
    "# - instead of knowing the exact size of the pool, the model just needs to know\n",
    "#   whether there's a pool or not.\n",
    "# - having a pool might increase a house's value disproportionately, regardless\n",
    "#   of the pool's size\n",
    "def add_binary_features(df):\n",
    "    df[\"haspool\"] = df[\"PoolArea\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "    df[\"has2ndfloor\"] = df[\"2ndFlrSF\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "    df[\"hasgarage\"] = df[\"GarageArea\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "    df[\"hasbsmt\"] = df[\"TotalBsmtSF\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "    df[\"hasfireplace\"] = df[\"Fireplaces\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2344,
   "id": "fd408afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new features:\n",
    "\n",
    "\n",
    "def add_aggr_features(df):\n",
    "    # combined effect of the age of the house and the recency of any remodeling:\n",
    "    # recently remodeled older house could be more valuable than an old house that\n",
    "    # hasn't been updated\n",
    "    df[\"YrBltAndRemod\"] = df[\"YearBuilt\"] + df[\"YearRemodAdd\"]\n",
    "\n",
    "    # total square footage of the house might be better indicator than individual\n",
    "    # measurements, as it gives a holistic view of the size of the house.\n",
    "    df[\"TotalSF\"] = (\n",
    "        df[\"TotalBsmtSF\"] + df[\"1stFlrSF\"] + df[\"2ndFlrSF\"]\n",
    "    )\n",
    "\n",
    "    # same as above for total ^2 footage across different levels of the house.\n",
    "    df[\"Total_sqr_footage\"] = (\n",
    "        df[\"BsmtFinSF1\"]\n",
    "        + df[\"BsmtFinSF2\"]\n",
    "        + df[\"1stFlrSF\"]\n",
    "        + df[\"2ndFlrSF\"]\n",
    "    )\n",
    "\n",
    "    # aggregates all types of bathrooms: full baths (with a shower or bathtub) are\n",
    "    # generally more valuable than half baths.\n",
    "    df[\"Total_Bathrooms\"] = (\n",
    "        df[\"FullBath\"]\n",
    "        + (0.5 * df[\"HalfBath\"])\n",
    "        + df[\"BsmtFullBath\"]\n",
    "        + (0.5 * df[\"BsmtHalfBath\"])\n",
    "    )\n",
    "\n",
    "    # combines all types of porches and decks to give an overall measure of the outdoor\n",
    "    # living space: Outdoor spaces can add significant value to a property.\n",
    "    df[\"Total_porch_sf\"] = (\n",
    "        df[\"OpenPorchSF\"]\n",
    "        + df[\"3SsnPorch\"]\n",
    "        + df[\"EnclosedPorch\"]\n",
    "        + df[\"ScreenPorch\"]\n",
    "        + df[\"WoodDeckSF\"]\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2390,
   "id": "15d0108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_features(df):\n",
    "    # remove unnecessary features or with very low variance\n",
    "    # ignore errors because train.csv &  AmesHousing.csv have different ID fields\n",
    "    df.drop(\n",
    "        [\n",
    "            \"Id\",\n",
    "            \"Street\",\n",
    "            \"Utilities\",\n",
    "            \"PoolQC\",\n",
    "            \"Order\",\n",
    "            \"PID\",\n",
    "        ],\n",
    "        axis=1,\n",
    "        inplace=True,\n",
    "        errors=\"ignore\",\n",
    "    )\n",
    "\n",
    "    # ℹ️ dimensionality reduction: removing the original features and keeping only\n",
    "    # the new ones improve the scores (probably because there is a bunch of ft!)\n",
    "    df.drop(\n",
    "        [\n",
    "            \"YearBuilt\",\n",
    "            \"YearRemodAdd\",\n",
    "            \"1stFlrSF\",\n",
    "            \"2ndFlrSF\",\n",
    "            \"BsmtFinSF1\",\n",
    "            \"BsmtFinSF2\",\n",
    "            \"FullBath\",\n",
    "            \"HalfBath\",\n",
    "            \"BsmtFullBath\",\n",
    "            \"BsmtHalfBath\",\n",
    "            \"OpenPorchSF\",\n",
    "            \"3SsnPorch\",\n",
    "            \"EnclosedPorch\",\n",
    "            \"ScreenPorch\",\n",
    "            \"WoodDeckSF\",\n",
    "        ],\n",
    "        axis=1,\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bdea55",
   "metadata": {},
   "source": [
    "### Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2346,
   "id": "a272f0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [# missing, % missing]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Process TRAIN data\n",
    "df_train = fill_nulls(df_train)\n",
    "df_train = add_binary_features(df_train)\n",
    "df_train = add_aggr_features(df_train)\n",
    "df_train = remove_features(df_train)\n",
    "\n",
    "# check if all nulls are handled\n",
    "show_missing_data(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe33ef1a",
   "metadata": {},
   "source": [
    "### Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2348,
   "id": "8d092586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(df):\n",
    "    \"\"\"Encode categorical features\"\"\"\n",
    "    columns_to_encode = df.select_dtypes(\n",
    "        include=[\"object\", \"category\"]\n",
    "    ).columns.tolist()\n",
    "    encoded_df_train = pd.get_dummies(df, columns=columns_to_encode, drop_first=True)\n",
    "\n",
    "    # replace spaces in df columns for lightxgb model\n",
    "    encoded_df_train.columns = encoded_df_train.columns.str.replace(\" \", \"_\")\n",
    "\n",
    "    return encoded_df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644e1e3a",
   "metadata": {},
   "source": [
    "### Split dataset into Train/Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2349,
   "id": "83b08510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "\n",
    "def scale_features(df: any, scaler_type: ScalerType):\n",
    "    scaler = RobustScaler() if scaler_type == ScalerType.ROBUST else StandardScaler()\n",
    "    numerical_cols = df.select_dtypes(\n",
    "        include=[\"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    ).columns\n",
    "    X_scaled = df.copy()\n",
    "    X_scaled[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2350,
   "id": "8ba4ce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = encode_features(df_train).drop(\"SalePrice\", axis=1)\n",
    "X = scale_features(X, ScalerType.ROBUST)\n",
    "# X = apply_yeojohnson(df_train.drop(\"SalePrice\", axis=1))\n",
    "\n",
    "y = np.log1p(df_train[\"SalePrice\"]) # log transformation\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2e601c",
   "metadata": {},
   "source": [
    "☝🏻 Robust scaler performs better than standard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8e9ab8",
   "metadata": {},
   "source": [
    "### Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2351,
   "id": "350311ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "def fit_xgb_regressor(\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.3,\n",
    "    max_depth=6,\n",
    "    min_child_weight=1,\n",
    "    n_estimators=100,\n",
    "    objective=\"reg:squarederror\",\n",
    "    reg_alpha=0,\n",
    "    scale_pos_weight=1,\n",
    "    subsample=1,\n",
    "):\n",
    "    xgb = XGBRegressor(\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_child_weight=min_child_weight,\n",
    "        gamma=gamma,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        objective=objective,\n",
    "        nthread=-1,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        seed=RANDOM_STATE,\n",
    "        reg_alpha=reg_alpha,\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "    return xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2352,
   "id": "94c6de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "def fit_ridge_regressor(\n",
    "    alpha=1.0,\n",
    "    fit_intercept=True,\n",
    "    max_iter=None,\n",
    "    tol=0.0001,\n",
    "):\n",
    "    ridge = Ridge(\n",
    "        alpha=alpha,\n",
    "        fit_intercept=fit_intercept,\n",
    "        copy_X=True,\n",
    "        max_iter=max_iter,\n",
    "        tol=tol,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "    ridge.fit(X_train, y_train)\n",
    "    return ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2353,
   "id": "c5ddce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "def fit_lasso_regressor(\n",
    "    alpha=1.0,\n",
    "    fit_intercept=True,\n",
    "    max_iter=1000,\n",
    "    positive=False,\n",
    "    precompute=False,\n",
    "    selection=\"cyclic\",\n",
    "    tol=0.0001,\n",
    "    warm_start=False,\n",
    "):\n",
    "    lasso = Lasso(\n",
    "        alpha=alpha,\n",
    "        fit_intercept=fit_intercept,\n",
    "        precompute=precompute,\n",
    "        copy_X=True,\n",
    "        max_iter=max_iter,\n",
    "        tol=tol,\n",
    "        warm_start=warm_start,\n",
    "        positive=positive,\n",
    "        random_state=RANDOM_STATE,\n",
    "        selection=selection,\n",
    "    )\n",
    "    lasso.fit(X_train, y_train)\n",
    "    return lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2354,
   "id": "19c19423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "\n",
    "def fit_elastic_net_regressor(\n",
    "    alpha=1.0,\n",
    "    fit_intercept=True,\n",
    "    l1_ratio=0.5,\n",
    "    max_iter=1000,\n",
    "    positive=False,\n",
    "    precompute=False,\n",
    "    selection=\"cyclic\",\n",
    "    tol=0.0001,\n",
    "    warm_start=False,\n",
    "):\n",
    "    enet = ElasticNet(\n",
    "        alpha=alpha,\n",
    "        l1_ratio=l1_ratio,\n",
    "        fit_intercept=fit_intercept,\n",
    "        precompute=precompute,\n",
    "        max_iter=max_iter,\n",
    "        copy_X=True,\n",
    "        tol=tol,\n",
    "        warm_start=warm_start,\n",
    "        positive=positive,\n",
    "        random_state=RANDOM_STATE,\n",
    "        selection=selection,\n",
    "    )\n",
    "    enet.fit(X_train, y_train)\n",
    "    return enet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2355,
   "id": "327740ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "def fit_lightgbm_regressor(\n",
    "    bagging_fraction=1.0,\n",
    "    bagging_freq=0,\n",
    "    colsample_bytree=1.0,\n",
    "    force_row_wise=False,\n",
    "    importance_type=\"split\",\n",
    "    learning_rate=0.1,\n",
    "    max_bin=255,\n",
    "    max_depth=-1,\n",
    "    min_child_samples=20,\n",
    "    min_split_gain=0.0,\n",
    "    n_estimators=100,\n",
    "    num_leaves=31,\n",
    "    objective=\"regression\",\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=0.0,\n",
    "    # subsample=1.0,\n",
    "    subsample_for_bin=200000,\n",
    "    subsample_freq=0,\n",
    "    verbose=1,\n",
    "):\n",
    "    lgbm = lgb.LGBMRegressor(\n",
    "        bagging_fraction=bagging_fraction,\n",
    "        bagging_freq=bagging_freq,\n",
    "        bagging_seed=RANDOM_STATE,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        force_row_wise=force_row_wise,\n",
    "        importance_type=importance_type,\n",
    "        learning_rate=learning_rate,\n",
    "        max_bin=max_bin,\n",
    "        max_depth=max_depth,\n",
    "        min_split_gain=min_split_gain,\n",
    "        min_child_samples=min_child_samples,\n",
    "        n_estimators=n_estimators,\n",
    "        n_jobs=-1,\n",
    "        num_leaves=num_leaves,\n",
    "        objective=objective,\n",
    "        random_state=RANDOM_STATE,\n",
    "        reg_alpha=reg_alpha,\n",
    "        reg_lambda=reg_lambda,\n",
    "        # subsample=subsample,\n",
    "        subsample_for_bin=subsample_for_bin,\n",
    "        subsample_freq=subsample_freq,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    lgbm.fit(X_train, y_train)\n",
    "    return lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2356,
   "id": "b9e6f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "def fit_gradient_boosting_regressor(\n",
    "    learning_rate=0.1,\n",
    "    loss='squared_error',\n",
    "    max_depth=3,\n",
    "    max_features=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=100,\n",
    "    subsample=1.0,\n",
    "):\n",
    "    gb = GradientBoostingRegressor(\n",
    "        loss=loss,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        max_features=max_features,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        min_samples_split=min_samples_split,\n",
    "        n_estimators=n_estimators,\n",
    "        random_state=RANDOM_STATE,\n",
    "        subsample=subsample,\n",
    "    )\n",
    "    gb.fit(X_train, y_train)\n",
    "    return gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a6504e",
   "metadata": {},
   "source": [
    "### Fit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2357,
   "id": "c81ed7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train regressors with default values\n",
    "xgb = fit_xgb_regressor()\n",
    "ridge = fit_ridge_regressor()\n",
    "lasso = fit_lasso_regressor()\n",
    "enet = fit_elastic_net_regressor()\n",
    "lgbm = fit_lightgbm_regressor(verbose=-1)\n",
    "gb = fit_gradient_boosting_regressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab0bfee",
   "metadata": {},
   "source": [
    "### Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2358,
   "id": "4c0ad97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold, cross_val_score\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "# def evaluate_models(regressors, cv=10):\n",
    "#     results = []\n",
    "#     kfolds = KFold(n_splits=cv, shuffle=True, random_state=RANDOM_STATE)\n",
    "#     for regressor in regressors:\n",
    "#         y_pred = regressor.predict(X_test)\n",
    "#         r2 = r2_score(y_test, y_pred)\n",
    "#         mae = mean_absolute_error(y_test, y_pred)\n",
    "#         mse = mean_squared_error(y_test, y_pred)\n",
    "#         rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#         rmse_cv = np.sqrt(\n",
    "#             -cross_val_score(\n",
    "#                 regressor, X, y, scoring=\"neg_mean_squared_error\", cv=kfolds\n",
    "#             )\n",
    "#         )\n",
    "#         results.append(\n",
    "#             {\n",
    "#                 \"Model\": type(regressor).__name__,\n",
    "#                 \"MAE\": mae,\n",
    "#                 \"MSE\": mse,\n",
    "#                 \"RMSE\": rmse,\n",
    "#                 \"RMSEcv\": rmse_cv.mean(),\n",
    "#                 \"R^2\": r2,\n",
    "#             }\n",
    "#         )\n",
    "#     sorted_results = sorted(results, key=lambda x: x[\"RMSEcv\"], reverse=False)\n",
    "#     print(f\"{'Model':<25} {'RMSEcv':<11} {'RMSE':<11} {'MAE':<8} {'MSE':<8} {'R^2':<8}\")\n",
    "#     print(\"-\" * 72)\n",
    "#     for result in sorted_results:\n",
    "#         metrics = f\"{result['RMSEcv']:<11.5f} {result['RMSE']:<11.5f} \"\n",
    "#         metrics += f\"{result['MAE']:<8.2f} {result['MSE']:<8.2f} {result['R^2']:<8.2f}\"\n",
    "#         print(f\"{result['Model']:<25} {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2359,
   "id": "a63cfbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "def evaluate_models(regressors, X, y, cv=10):\n",
    "    results = []\n",
    "    kfolds = KFold(n_splits=cv, shuffle=True, random_state=RANDOM_STATE)\n",
    "    for regressor in regressors:\n",
    "        y_pred = regressor.predict(X)\n",
    "        r2 = r2_score(y, y_pred)\n",
    "        mae = mean_absolute_error(y, y_pred)\n",
    "        mse = mean_squared_error(y, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "        rmse_cv = np.sqrt(\n",
    "            -cross_val_score(\n",
    "                regressor, X, y, scoring=\"neg_mean_squared_error\", cv=kfolds\n",
    "            )\n",
    "        )\n",
    "        results.append(\n",
    "            {\n",
    "                \"Model\": type(regressor).__name__,\n",
    "                \"MAE\": mae,\n",
    "                \"MSE\": mse,\n",
    "                \"RMSE\": rmse,\n",
    "                \"RMSEcv\": rmse_cv.mean(),\n",
    "                \"R^2\": r2,\n",
    "            }\n",
    "        )\n",
    "    sorted_results = sorted(results, key=lambda x: x[\"RMSEcv\"], reverse=False)\n",
    "    print(f\"{'Model':<25} {'RMSEcv':<11} {'RMSE':<11} {'MAE':<8} {'MSE':<8} {'R^2':<8}\")\n",
    "    print(\"-\" * 72)\n",
    "    for result in sorted_results:\n",
    "        metrics = f\"{result['RMSEcv']:<11.5f} {result['RMSE']:<11.5f} \"\n",
    "        metrics += f\"{result['MAE']:<8.2f} {result['MSE']:<8.2f} {result['R^2']:<8.2f}\"\n",
    "        print(f\"{result['Model']:<25} {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2360,
   "id": "795c9a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_learning_curve(\n",
    "    estimator,\n",
    "    X= X,\n",
    "    y = y,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "    fig_size=(6, 4),\n",
    "):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        n_jobs=n_jobs,\n",
    "        train_sizes=train_sizes,\n",
    "    )\n",
    "\n",
    "    # Take the negative of the scores because 'neg_mean_squared_error' is used\n",
    "    train_scores_mean = np.sqrt(-np.mean(train_scores, axis=1))\n",
    "    test_scores_mean = np.sqrt(-np.mean(test_scores, axis=1))\n",
    "\n",
    "    sns.lineplot(x=train_sizes, y=train_scores_mean, label=\"Training score\")\n",
    "    sns.lineplot(x=train_sizes, y=test_scores_mean, label=\"Cross-validation score\")\n",
    "\n",
    "    plt.title(f\"Learning Curve (RMSE) - {type(estimator).__name__}\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2361,
   "id": "11c5bd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def evaluate_model_grid_search_cv(\n",
    "    regressor,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    params,\n",
    "    cv=10,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "):\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=regressor, param_grid=params, scoring=scoring, cv=cv, n_jobs=n_jobs\n",
    "    )\n",
    "    grid_search.fit(X=X_train, y=y_train)\n",
    "    best_score = np.sqrt(-grid_search.best_score_)\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Model: {type(regressor).__name__}\")\n",
    "    print(f\" - Best RMSE: {best_score}\")\n",
    "    print(f\" - Best params: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801ca983",
   "metadata": {},
   "source": [
    "### Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2362,
   "id": "636d5c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                     RMSEcv      RMSE        MAE      MSE      R^2     \n",
      "------------------------------------------------------------------------\n",
      "Ridge                     0.13224     0.11579     0.08     0.01     0.92    \n",
      "GradientBoostingRegressor 0.15578     0.11152     0.08     0.01     0.93    \n",
      "LGBMRegressor             0.15841     0.11338     0.08     0.01     0.93    \n",
      "XGBRegressor              0.17189     0.12338     0.09     0.02     0.91    \n",
      "Lasso                     0.42599     0.41668     0.33     0.17     -0.00   \n",
      "ElasticNet                0.42908     0.41683     0.33     0.17     -0.00   \n"
     ]
    }
   ],
   "source": [
    "models = [xgb, ridge, lasso, enet, lgbm, gb]\n",
    "evaluate_models(models, X_test, y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2363,
   "id": "275eda84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_learning_curve(xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea84e49",
   "metadata": {},
   "source": [
    "### Tune Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee0baf1",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2364,
   "id": "0d18f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"colsample_bytree\": [0.7],\n",
    "#     \"gamma\": [0],\n",
    "#     \"learning_rate\": [0.01, 0.05],\n",
    "#     \"max_depth\": [2, 3],\n",
    "#     \"min_child_weight\": [0],\n",
    "#     \"n_estimators\": [2500, 3460],\n",
    "#     \"objective\": [\"reg:squarederror\"],\n",
    "#     \"reg_alpha\": [0.00006],\n",
    "#     \"scale_pos_weight\": [1],\n",
    "#     \"subsample\": [0.7, 0.8],\n",
    "# }\n",
    "\n",
    "# evaluate_model_grid_search_cv(xgb, X_train, y_train, params, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2365,
   "id": "fc5dba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb = fit_xgb_regressor(\n",
    "#     0.01, 3460, 3, 0, 0, 0.7, 0.7, \"reg:squarederror\", 1, 0.00006\n",
    "# )  # rmse: 0.12\n",
    "xgb = fit_xgb_regressor(\n",
    "    colsample_bytree=0.7,\n",
    "    gamma=0,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=3,\n",
    "    min_child_weight=0,\n",
    "    n_estimators=3460,\n",
    "    objective=\"reg:squarederror\",\n",
    "    reg_alpha=0.00006,\n",
    "    scale_pos_weight=1,\n",
    "    subsample=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e8381",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2366,
   "id": "8828221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Ridge\n",
      " - Best RMSE: 0.11250925420687193\n",
      " - Best params: {'alpha': 13, 'fit_intercept': True, 'max_iter': None, 'tol': 1e-06}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"alpha\": [12.8, 12.9, 13],\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"max_iter\": [None, 500, 1000, 5000],\n",
    "    \"tol\": [0.000001, 0.0000025, 0.000005, 0.00001, 0.00002],\n",
    "}\n",
    "\n",
    "\n",
    "evaluate_model_grid_search_cv(ridge, X_train, y_train, params, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2367,
   "id": "3a29cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = fit_ridge_regressor(\n",
    "    alpha=13,\n",
    "    fit_intercept=True,\n",
    "    max_iter=None,\n",
    "    tol=0.000005,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140fb146",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2368,
   "id": "774f3b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"alpha\": [0.0001, 0.001], \n",
    "#     \"fit_intercept\": [True, False],\n",
    "#     \"max_iter\": [1000, 2000],\n",
    "#     \"positive\": [False, True],\n",
    "#     \"precompute\": [False, True],\n",
    "#     \"tol\": [0.00001, 0.0001],\n",
    "#     \"selection\": [\"cyclic\", \"random\"],\n",
    "#     \"warm_start\": [False, True],\n",
    "# }\n",
    "\n",
    "\n",
    "# evaluate_model_grid_search_cv(lasso, X_train, y_train, params, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2369,
   "id": "cce4073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = fit_lasso_regressor(\n",
    "    alpha=0.0001,\n",
    "    fit_intercept=True,\n",
    "    max_iter=7500,\n",
    "    positive=True,\n",
    "    precompute=False,\n",
    "    selection=\"random\",\n",
    "    tol=0.00001,\n",
    "    warm_start=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6ac4e5",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2370,
   "id": "2cc590ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"alpha\": [0.0001, 0.00015, 0.0002],\n",
    "#     \"fit_intercept\": [True],\n",
    "#     \"l1_ratio\": [0.8, 0.9],\n",
    "#     \"max_iter\": [12000],\n",
    "#     \"positive\": [True],\n",
    "#     \"precompute\": [False, True],\n",
    "#     \"selection\": [\"cyclic\", \"random\"],\n",
    "#     \"tol\": [0.000001, 0.00001],\n",
    "#     \"warm_start\": [False],\n",
    "# }\n",
    "\n",
    "# evaluate_model_grid_search_cv(enet, X_train, y_train, params, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2371,
   "id": "df5219ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "enet = fit_elastic_net_regressor(\n",
    "    alpha=0.00015,\n",
    "    fit_intercept=True,\n",
    "    l1_ratio=0.8,\n",
    "    max_iter=12000,\n",
    "    positive=True,\n",
    "    precompute=False,\n",
    "    selection=\"random\",\n",
    "    tol=0.00001,\n",
    "    warm_start=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d64f482",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2372,
   "id": "fd0c048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"bagging_fraction\": [0.8], # 0.8 in 0.9,1.0\n",
    "    \"bagging_freq\": [4], # 4 in 0,4\n",
    "    \"colsample_bytree\": [0.8], # 0.8 in 0.9\n",
    "    \"importance_type\": [\"split\"], # \"gain\"\n",
    "    \"force_row_wise\": [True], # False\n",
    "    \"learning_rate\": [0.01],\n",
    "    \"max_bin\": [200], # set to 200!!\n",
    "    \"max_depth\": [-1],\n",
    "    \"min_child_samples\": [10], ## !! decreasing it increases a lot the running time\n",
    "    \"min_split_gain\": [0.0], # gets 0.1 from 0.1, 0.2, 0.3\n",
    "    \"n_estimators\": [2000],\n",
    "    \"num_leaves\": [4], # set to 4!!\n",
    "    \"objective\": [\"regression\"],\n",
    "    \"reg_alpha\": [0.0],\n",
    "    \"reg_lambda\": [0.0],\n",
    "    # \"subsample\": [0.8], # remove if using bagging\n",
    "    \"subsample_for_bin\": [200000],\n",
    "    \"subsample_freq\": [0],\n",
    "    \"verbose\": [-1], # only warnings\n",
    "}\n",
    "\n",
    "# evaluate_model_grid_search_cv(lgbm, X_train, y_train, params, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2373,
   "id": "d2a8ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = fit_lightgbm_regressor(\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=4,\n",
    "    colsample_bytree=0.8,\n",
    "    force_row_wise=True,\n",
    "    importance_type='split',\n",
    "    learning_rate=0.01,\n",
    "    max_bin=200,\n",
    "    max_depth=-1,\n",
    "    min_split_gain=0.0,\n",
    "    min_child_samples=10,\n",
    "    n_estimators=6000,\n",
    "    num_leaves=4,\n",
    "    objective=\"regression\",\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=0.0,\n",
    "    subsample_for_bin=200000,\n",
    "    subsample_freq=0,\n",
    "    verbose=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877ea14",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2374,
   "id": "4d0d171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"loss\": ['squared_error', 'huber'],\n",
    "    \"n_estimators\": [2000],\n",
    "    \"learning_rate\": [0.01],\n",
    "    \"max_depth\": [4],\n",
    "    \"min_samples_leaf\": [7, 8, 9],\n",
    "    \"min_samples_split\": [2, 3],\n",
    "    \"subsample\": [0.9],\n",
    "    \"max_features\": ['sqrt'], \n",
    "}\n",
    "\n",
    "# evaluate_model_grid_search_cv(gb, X_train, y_train, params, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2375,
   "id": "07b48b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTO PREVENT OVERFITTING\\n'"
      ]
     },
     "execution_count": 2375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = fit_gradient_boosting_regressor(\n",
    "    loss='huber',\n",
    "    learning_rate=0.01,\n",
    "    max_depth=4,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=8,\n",
    "    n_estimators=3000,\n",
    "    subsample=0.9,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "TO PREVENT OVERFITTING\n",
    "\"\"\"\n",
    "# gb = fit_gradient_boosting_regressor(\n",
    "#     loss='huber',\n",
    "#     learning_rate=0.005,  # Decreased\n",
    "#     max_depth=3,  # Decreased\n",
    "#     max_features='sqrt',\n",
    "#     min_samples_leaf=4,  # Increased\n",
    "#     min_samples_split=10,  # Increased\n",
    "#     n_estimators=3000,  # Decreased\n",
    "#     subsample=0.7,  # Decreased\n",
    "#     validation_fraction=0.1,  # For early stopping\n",
    "#     n_iter_no_change=20  # For early stopping\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# quite overfitting, so will have to lower it although score decreases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7646633b",
   "metadata": {},
   "source": [
    "### Scores with tunned models on Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2376,
   "id": "c89fd444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                     RMSEcv      RMSE        MAE      MSE      R^2     \n",
      "------------------------------------------------------------------------\n",
      "ElasticNet                0.10762     0.09262     0.07     0.01     0.94    \n",
      "Lasso                     0.10763     0.09190     0.07     0.01     0.94    \n",
      "GradientBoostingRegressor 0.11118     0.05337     0.03     0.00     0.98    \n",
      "XGBRegressor              0.11142     0.04353     0.03     0.00     0.99    \n",
      "Ridge                     0.11168     0.09509     0.07     0.01     0.94    \n"
     ]
    }
   ],
   "source": [
    "models = [xgb, ridge, lasso, enet, gb] # excluding lgbm for now, takes some time.\n",
    "evaluate_models(models, X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2377,
   "id": "967c68d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_learning_curve(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2378,
   "id": "62592aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_learning_curve(gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52562ebc",
   "metadata": {},
   "source": [
    "### Kaggle check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2422,
   "id": "44e8aaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>526301100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>526350040</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MSSubClass MSZoning  LotFrontage  LotArea Street Alley  \\\n",
       "0      1  526301100          20       RL        141.0    31770   Pave   NaN   \n",
       "1      2  526350040          20       RH         80.0    11622   Pave   NaN   \n",
       "\n",
       "  LotShape LandContour  ... PoolArea PoolQC  Fence MiscFeature MiscVal MoSold  \\\n",
       "0      IR1         Lvl  ...        0    NaN    NaN         NaN       0      5   \n",
       "1      Reg         Lvl  ...        0    NaN  MnPrv         NaN       0      6   \n",
       "\n",
       "  YrSold SaleType  SaleCondition  SalePrice  \n",
       "0   2010      WD          Normal     215000  \n",
       "1   2010      WD          Normal     105000  \n",
       "\n",
       "[2 rows x 82 columns]"
      ]
     },
     "execution_count": 2422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"./data/AmesHousing.csv\")\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2423,
   "id": "03def07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             # missing  % missing\n",
      "LotFrontage        487      16.69\n"
     ]
    }
   ],
   "source": [
    "# Process TEST data\n",
    "df_test = fill_nulls(df_test)\n",
    "df_test = add_binary_features(df_test)\n",
    "df_test = add_aggr_features(df_test)\n",
    "df_test = remove_features(df_test)\n",
    "\n",
    "# check if all nulls are handled\n",
    "show_missing_data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2425,
   "id": "4cecb4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = encode_features(df_test).drop(\"SalePrice\", axis=1)\n",
    "X_test = scale_features(X_test, ScalerType.ROBUST)\n",
    "\n",
    "y_test = np.log1p(df_test[\"SalePrice\"])\n",
    "\n",
    "evaluate_models(models, X_test, y_test, 2) # needs params x & y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79576c80",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb170f3f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a16f605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, boxcox_normmax\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "def apply_boxcox(df):\n",
    "    \"\"\"\n",
    "    Apply Box-Cox transformation to numerical features with skewness > 0.5 \n",
    "    \"\"\"\n",
    "    # Assuming 'features' is your DataFrame\n",
    "    numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    numerics = [feature for feature in df.columns if df[feature].dtype in numeric_dtypes]\n",
    "\n",
    "    # Calculate skewness and select highly skewed features\n",
    "    skewness = df[numerics].apply(lambda x: skew(x.dropna()))\n",
    "    high_skewness = skewness[abs(skewness) > 0.5]\n",
    "    high_skew_features = high_skewness.index\n",
    "\n",
    "    # Apply Box-Cox transformation to highly skewed features\n",
    "    for feature in high_skew_features:\n",
    "        # Adding 1 to the feature values to ensure positivity as boxcox1p requires positive values\n",
    "        df[feature] = boxcox1p(df[feature], boxcox_normmax(df[feature] + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cb41dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16a39da8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "628305c3",
   "metadata": {},
   "source": [
    "`RobustScaler` and Box-Cox transformation are not equivalent; they are different methods used for different purposes in data preprocessing:\n",
    "\n",
    "1. **RobustScaler**:\n",
    "   - Purpose: `RobustScaler` is used for scaling features to a similar range. It's especially useful when you have outliers in your dataset because it uses the median and the interquartile range (IQR) for scaling, which are less sensitive to outliers than the mean and standard deviation.\n",
    "   - Operation: It subtracts the median and then divides by the IQR. Specifically, the IQR is the range between the 1st quartile (25th quantile) and the 3rd quartile (75th quantile).\n",
    "   - Formula: \\[ \\text{scaled} \\, x = \\frac{x - \\text{median}(x)}{\\text{IQR}(x)} \\]\n",
    "   - Usage: Common in machine learning pipelines to standardize numerical features, especially for algorithms sensitive to the scale of input features (like linear models, k-NN, SVMs with RBF kernel, etc.).\n",
    "\n",
    "2. **Box-Cox Transformation**:\n",
    "   - Purpose: The Box-Cox transformation is a family of power transformations used to stabilize variance and make the data more closely follow a normal distribution. It's particularly helpful when you have non-normally distributed data or non-constant variance (heteroscedasticity).\n",
    "   - Operation: It transforms a variable to a new value (often closer to a normal distribution). The transformation is defined for positive values only.\n",
    "   - Formula: A parameter λ is found that best normalizes the data. For different λ values, the transformation varies (for example, λ=0 corresponds to a log transformation).\n",
    "   - Usage: Often used in regression and other statistical modeling to meet the assumption of normality or homoscedasticity.\n",
    "\n",
    "### Should You Use Both?\n",
    "\n",
    "- **Depends on Data and Model**: Whether to use one or both depends on your data and the model you are using. If your primary concern is about scaling features in the presence of outliers, `RobustScaler` is appropriate. If your concern is about normalizing data distribution (especially for linear regression models), Box-Cox might be more suitable.\n",
    "- **Not Always Necessary Together**: They serve different purposes, so you don't necessarily need to apply both. In many cases, just one of these transformations (chosen based on your specific data characteristics and modeling needs) is sufficient.\n",
    "- **Model Requirements**: Consider the assumptions and requirements of the models you plan to use. For instance, linear regression models assume normally distributed errors and may benefit more from a Box-Cox transformation, while algorithms like SVM or k-NN might benefit more from `RobustScaler`.\n",
    "\n",
    "### Which One to Use?\n",
    "\n",
    "- If you're dealing with outliers and need to scale your features, go with `RobustScaler`.\n",
    "- If your main concern is about transforming your feature distribution to be more normal-like, especially for linear models, consider Box-Cox transformation.\n",
    "- Always validate your choice with model performance. You can experiment with both and see which one (or the combination) improves your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765723d8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
