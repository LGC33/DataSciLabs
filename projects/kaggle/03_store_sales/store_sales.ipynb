{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a5f8fc4",
   "metadata": {},
   "source": [
    "# Store Sales - Time Series Forecasting\n",
    "*Use machine learning to predict grocery sales*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2166,
   "id": "1b8fd1e7-2a7f-48ea-9bf0-2e4aa8d36cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "RANDOM_STATE = 101\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a023db",
   "metadata": {},
   "source": [
    "### Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2167,
   "id": "5ef38fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000888, 6)"
      ]
     },
     "execution_count": 2167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\n",
    "    \"./data/train.csv\",\n",
    "    usecols=[\"id\", \"date\", \"store_nbr\", \"family\", \"sales\", \"onpromotion\"],\n",
    "    dtype={\n",
    "        \"store_nbr\": \"category\",\n",
    "        \"family\": \"category\",\n",
    "        \"sales\": \"float32\",\n",
    "        \"onpromotion\": \"uint32\",\n",
    "    },\n",
    "    parse_dates=[\"date\"],\n",
    ")\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2168,
   "id": "d596ae4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000886</th>\n",
       "      <td>3000886</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>SCHOOL AND OFFICE SUPPLIES</td>\n",
       "      <td>121.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000887</th>\n",
       "      <td>3000887</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id       date store_nbr                      family  sales  \\\n",
       "0              0 2013-01-01         1                  AUTOMOTIVE    0.0   \n",
       "1              1 2013-01-01         1                   BABY CARE    0.0   \n",
       "3000886  3000886 2017-08-15         9  SCHOOL AND OFFICE SUPPLIES  121.0   \n",
       "3000887  3000887 2017-08-15         9                     SEAFOOD   16.0   \n",
       "\n",
       "         onpromotion  \n",
       "0                  0  \n",
       "1                  0  \n",
       "3000886            8  \n",
       "3000887            0  "
      ]
     },
     "execution_count": 2168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df_train.head(2), df_train.tail(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2169,
   "id": "5850617a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28512, 5)"
      ]
     },
     "execution_count": 2169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"./data/test.csv\",\n",
    "    usecols=[\"id\", \"date\", \"store_nbr\", \"family\", \"onpromotion\"],\n",
    "    dtype={\n",
    "        \"store_nbr\": \"category\",\n",
    "        \"family\": \"category\",\n",
    "        \"onpromotion\": \"uint32\",\n",
    "    },\n",
    "    parse_dates=[\"date\"],\n",
    ")\n",
    "\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2170,
   "id": "e283e942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000888</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000889</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28510</th>\n",
       "      <td>3029398</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>SCHOOL AND OFFICE SUPPLIES</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28511</th>\n",
       "      <td>3029399</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id       date store_nbr                      family  onpromotion\n",
       "0      3000888 2017-08-16         1                  AUTOMOTIVE            0\n",
       "1      3000889 2017-08-16         1                   BABY CARE            0\n",
       "28510  3029398 2017-08-31         9  SCHOOL AND OFFICE SUPPLIES            9\n",
       "28511  3029399 2017-08-31         9                     SEAFOOD            0"
      ]
     },
     "execution_count": 2170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df_test.head(2), df_test.tail(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2171,
   "id": "a21f0aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 6)"
      ]
     },
     "execution_count": 2171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_holidays = pd.read_csv(\n",
    "    \"./data/holidays_events.csv\",\n",
    "    # dtype={\n",
    "    #     \"type\": \"category\",\n",
    "    #     \"locale\": \"category\",\n",
    "    # },\n",
    "    parse_dates=[\"date\"],\n",
    "    # index_col=\"date\",\n",
    ")\n",
    "\n",
    "df_holidays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2172,
   "id": "c7bd300c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>locale</th>\n",
       "      <th>locale_name</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Manta</td>\n",
       "      <td>Fundacion de Manta</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Cotopaxi</td>\n",
       "      <td>Provincializacion de Cotopaxi</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>2017-12-25</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Navidad</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>Additional</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Navidad+1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date        type    locale locale_name  \\\n",
       "0   2012-03-02     Holiday     Local       Manta   \n",
       "1   2012-04-01     Holiday  Regional    Cotopaxi   \n",
       "348 2017-12-25     Holiday  National     Ecuador   \n",
       "349 2017-12-26  Additional  National     Ecuador   \n",
       "\n",
       "                       description  transferred  \n",
       "0               Fundacion de Manta        False  \n",
       "1    Provincializacion de Cotopaxi        False  \n",
       "348                        Navidad        False  \n",
       "349                      Navidad+1        False  "
      ]
     },
     "execution_count": 2172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df_holidays.head(2), df_holidays.tail(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2173,
   "id": "dfd63ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 6)"
      ]
     },
     "execution_count": 2173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stores = pd.read_csv(\n",
    "    \"./data/stores.csv\",\n",
    "    dtype={\n",
    "        \"store_nbr\": \"category\",\n",
    "        \"city\": \"category\",\n",
    "        \"state\": \"category\",\n",
    "        \"type\": \"category\",\n",
    "        \"cluster\": \"category\",\n",
    "    },\n",
    ")\n",
    "\n",
    "df_holidays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2174,
   "id": "64ab175d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>Manta</td>\n",
       "      <td>Manabi</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>El Carmen</td>\n",
       "      <td>Manabi</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_nbr       city      state type cluster\n",
       "0          1      Quito  Pichincha    D      13\n",
       "1          2      Quito  Pichincha    D      13\n",
       "52        53      Manta     Manabi    D      13\n",
       "53        54  El Carmen     Manabi    C       3"
      ]
     },
     "execution_count": 2174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df_stores.head(2), df_stores.tail(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2175,
   "id": "1e7dc922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1218, 2)"
      ]
     },
     "execution_count": 2175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oil = pd.read_csv(\n",
    "    \"./data/oil.csv\",\n",
    "    parse_dates=[\"date\"],\n",
    "    # index_col=\"date\",\n",
    ")\n",
    "\n",
    "df_oil.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2176,
   "id": "2d205aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>dcoilwtico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>93.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>45.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>47.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  dcoilwtico\n",
       "0    2013-01-01         NaN\n",
       "1    2013-01-02       93.14\n",
       "1216 2017-08-30       45.96\n",
       "1217 2017-08-31       47.26"
      ]
     },
     "execution_count": 2176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df_oil.head(2), df_oil.tail(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2177,
   "id": "66ac3598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83488, 3)"
      ]
     },
     "execution_count": 2177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_txns = pd.read_csv(\n",
    "    \"./data/transactions.csv\",\n",
    "    dtype={\n",
    "        \"store_nbr\": \"category\",\n",
    "        \"transactions\": \"uint32\",\n",
    "    },\n",
    "    parse_dates=[\"date\"],\n",
    "    # index_col=\"date\",\n",
    ")\n",
    "\n",
    "df_txns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2178,
   "id": "450d53c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83486</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>53</td>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83487</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>54</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date store_nbr  transactions\n",
       "0     2013-01-01        25           770\n",
       "1     2013-01-02         1          2111\n",
       "83486 2017-08-15        53           932\n",
       "83487 2017-08-15        54           802"
      ]
     },
     "execution_count": 2178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df_txns.head(2), df_txns.tail(2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda0ef63",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb880a3",
   "metadata": {},
   "source": [
    "#### Check nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2179,
   "id": "43282994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_missing_data(df, df_name):\n",
    "    \"\"\"\n",
    "    Display number and percentage of columns with any missing value\n",
    "    \"\"\"\n",
    "    total = df.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (\n",
    "        ((df.isnull().sum() / df.isnull().count()) * 100)\n",
    "        .sort_values(ascending=False)\n",
    "        .round(2)\n",
    "    )\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=[\"# missing\", \"% missing\"])\n",
    "    \n",
    "    if missing_data[\"# missing\"].max() > 0:\n",
    "        print(f'`{df_name}` has null values:')\n",
    "        print(missing_data[missing_data[\"# missing\"] > 0])\n",
    "    else:\n",
    "        print(f'`{df_name}` does not have null values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2180,
   "id": "3b1de52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`df_train` does not have null values\n",
      "`df_test` does not have null values\n",
      "`df_txns` does not have null values\n",
      "`df_holidays` does not have null values\n",
      "`df_oil` has null values:\n",
      "            # missing  % missing\n",
      "dcoilwtico         43       3.53\n"
     ]
    }
   ],
   "source": [
    "show_missing_data(df_train, 'df_train')\n",
    "show_missing_data(df_test, 'df_test')\n",
    "show_missing_data(df_txns, 'df_txns')\n",
    "show_missing_data(df_holidays, 'df_holidays')\n",
    "show_missing_data(df_oil, 'df_oil')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea75b92",
   "metadata": {},
   "source": [
    "### Data cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b31a6e",
   "metadata": {},
   "source": [
    "#### Manage nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2181,
   "id": "31fe5dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Careful!! there can be 3 days in a row without values.\n",
    "# -> TO BE UPDATED TO FIND ITERATIVELLY THE NEAREST VALUE.\n",
    "\n",
    "def fill_missing_with_surrounding_mean(df, target_column, min_periods=2, decimals=2):\n",
    "    \"\"\"\n",
    "    fill null values on field `target_column` with their surrounding `min_periods` peers\n",
    "    \"\"\"\n",
    "    # Calculate the rolling mean with the specified minimum number of periods\n",
    "    rolling_mean = (\n",
    "        df[target_column]\n",
    "        .rolling(window=min_periods * 2 + 1, min_periods=min_periods, center=True)\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    # Round the rolling mean to the specified number of decimal places\n",
    "    rounded_mean = rolling_mean.round(decimals)\n",
    "\n",
    "    # Fill missing values in the target column with the rolling mean\n",
    "    df[target_column].fillna(rounded_mean, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Alternatively:\n",
    "# df_oil['dcoilwtico'].fillna(method='backfill', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ace6b2",
   "metadata": {},
   "source": [
    "### Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2182,
   "id": "0fe232ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_oil = fill_missing_with_surrounding_mean(df_oil, 'dcoilwtico', 1)\n",
    "# show_missing_data(df_oil, 'df_oil')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6fd5cb",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2183,
   "id": "73d2e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyses will be done at (entire) day level, where specific time is not relevant,\n",
    "# so converting to Period object\n",
    "\n",
    "# but... according to gpt: in the context of time series modeling, especially when \n",
    "# using functions like DeterministicProcess from statsmodels, it's generally more \n",
    "# straightforward to keep dates as a DateTime type rather than converting them to\n",
    "#  a Period. The DateTimeIndex in pandas is more widely supported for time series \n",
    "# analysis and makes certain operations more straightforward.\n",
    "\n",
    "# df_train['date'] = df_train.date.dt.to_period('D')\n",
    "# df_test['date'] = df_test.date.dt.to_period('D')\n",
    "# df_holidays['date'] = df_holidays.date.dt.to_period('D')\n",
    "# df_oil['date'] = df_oil.date.dt.to_period('D')\n",
    "# df_txns['date'] = df_txns.date.dt.to_period('D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2184,
   "id": "8bd812d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(np.log1p(df_train['sales']), kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2185,
   "id": "5280db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['sales'].plot(figsize=(10, 6))\n",
    "# plt.title('Sales over Time')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2186,
   "id": "90fe7aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5,3))\n",
    "# sns.lineplot(data=df_oil, x='date', y='dcoilwtico')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42debdc7",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2187,
   "id": "3a4b5f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_features(df, lags):\n",
    "    for lag in lags:\n",
    "        # Create column 'sales_t-lag' by taking previous values ​​of column 'sales' based on columns 'store_nbr' and 'family'\n",
    "        df[f\"sales_t-{lag}\"] = df.groupby([\"store_nbr\", \"family\"])[\"sales\"].transform(\n",
    "            lambda x: x.shift(lag)\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2188,
   "id": "1a9d6092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na(df):\n",
    "    df[\"holiday_type\"] = df[\"holiday_type\"].fillna(\"Common\")\n",
    "    df[\"locale\"] = df[\"locale\"].fillna(\"Common\")\n",
    "    df[\"description\"] = df[\"description\"].fillna(\"Unknown\")\n",
    "    df[\"transferred\"] = df[\"transferred\"].fillna(False)\n",
    "    # TODO: to be replaced by fill_missing_with_surrounding_mean()\n",
    "    df[\"dcoilwtico\"] = df[\"dcoilwtico\"].fillna(method=\"backfill\")\n",
    "    df[\"transactions\"] = df[\"transactions\"].fillna(0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2189,
   "id": "55c35ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(df):\n",
    "    df = (\n",
    "        df.merge(df_stores, left_on=\"store_nbr\", right_on=\"store_nbr\", how=\"left\")\n",
    "        .rename(columns={\"type\": \"store_type\"})\n",
    "        .merge(\n",
    "            df_txns,\n",
    "            left_on=[\"date\", \"store_nbr\"],\n",
    "            right_on=[\"date\", \"store_nbr\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .merge(df_holidays, left_on=\"date\", right_on=\"date\", how=\"left\")\n",
    "        .drop_duplicates(subset=\"id\")\n",
    "        .rename(columns={\"type\": \"holiday_type\"})\n",
    "        .merge(df_oil, left_on=\"date\", right_on=\"date\", how=\"left\")\n",
    "    )\n",
    "    return df.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2190,
   "id": "b144ebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_features(df):\n",
    "    df[\"month\"] = df[\"date\"].dt.month\n",
    "    df[\"day_of_month\"] = df[\"date\"].dt.day\n",
    "    df[\"day_of_year\"] = df[\"date\"].dt.dayofyear\n",
    "    # df[\"week_of_year\"] = df[\"date\"].dt.isocalendar().week\n",
    "    df[\"day_of_week\"] = df[\"date\"].dt.dayofweek\n",
    "    df[\"year\"] = df[\"date\"].dt.year\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2191,
   "id": "fd8dc384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_features2(df):\n",
    "    # Convert PeriodIndex to DateTimeIndex\n",
    "    datetime_index = df.index.to_timestamp()\n",
    "\n",
    "    # Create date features\n",
    "    df[\"month\"] = datetime_index.month\n",
    "    df[\"day_of_month\"] = datetime_index.day\n",
    "    df[\"day_of_year\"] = datetime_index.dayofyear\n",
    "    # df[\"week_of_year\"] = datetime_index.isocalendar().week.astype('int')\n",
    "    df[\"day_of_week\"] = datetime_index.dayofweek\n",
    "    df[\"year\"] = datetime_index.year\n",
    "    df[\"new_year\"] = datetime_index.dayofyear == 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2192,
   "id": "32b675e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_noise(dataframe):\n",
    "    \"\"\"\n",
    "    Generate random noise with a normal distribution (mean=0, std=2)\n",
    "    matching the length of the dataframe.\n",
    "    \"\"\"\n",
    "    return np.random.normal(scale=2.0, size=(len(dataframe),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2193,
   "id": "73ebfe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_mean_features(dataframe, windows):\n",
    "    \"\"\"\n",
    "    Calculate rolling mean with triangular window and custom\n",
    "    noise for 'sales' within 'store_nbr' and 'family' groups.\n",
    "    \"\"\"\n",
    "    def add_noise(x):\n",
    "        return x + np.random.normal(size=len(x))\n",
    "\n",
    "    for window in windows:\n",
    "        dataframe[\"sales_roll_mean_\" + str(window)] = dataframe.groupby(\n",
    "            [\"store_nbr\", \"family\"]\n",
    "        )[\"sales\"].transform(\n",
    "            lambda x: x.shift(16)\n",
    "            .rolling(window=window, min_periods=7, win_type=\"triang\")\n",
    "            .mean()\n",
    "        )\n",
    "        dataframe[\"sales_roll_mean_\" + str(window)] = dataframe.groupby(\n",
    "            [\"store_nbr\", \"family\"]\n",
    "        )[\"sales_roll_mean_\" + str(window)].transform(add_noise)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2194,
   "id": "22f0567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewma_features(dataframe, alphas, lags):\n",
    "    \"\"\"\n",
    "    Create Exponentially Weighted Moving Average (EWMA) features for 'sales'\n",
    "    with specified alphas and lags, grouped by 'store_nbr' and 'family'.\n",
    "    \"\"\"\n",
    "    for alpha in alphas:\n",
    "        for lag in lags:\n",
    "            feature_name = (\n",
    "                \"sales_ewm_alpha_\" + str(alpha).replace(\".\", \"\") + \"_lag_\" + str(lag)\n",
    "            )\n",
    "            dataframe[feature_name] = dataframe.groupby([\"store_nbr\", \"family\"])[\n",
    "                \"sales\"\n",
    "            ].transform(lambda x: x.shift(lag).ewm(alpha=alpha, min_periods=1).mean())\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2195,
   "id": "0192756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose relevant features for regression models\n",
    "col = [\n",
    "    \"date\",\n",
    "    \"store_nbr\",\n",
    "    \"family\",\n",
    "    \"sales\",\n",
    "    \"onpromotion\",\n",
    "    \"cluster\",\n",
    "    \"holiday_type\",\n",
    "    \"locale\",\n",
    "    # \"description\",\n",
    "    \"transferred\",\n",
    "    \"dcoilwtico\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2196,
   "id": "7a57f0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1d/ty_knwmj61b4d3qs091tfglm0000gn/T/ipykernel_15670/1010387790.py:7: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[\"dcoilwtico\"] = df[\"dcoilwtico\"].fillna(method=\"backfill\")\n"
     ]
    }
   ],
   "source": [
    "df_train['sales'] = np.log1p(df_train['sales'])\n",
    "\n",
    "df_both = pd.concat([df_train, df_test], axis=0)\n",
    "df_both = merge_data(df_both)\n",
    "df_both = fill_na(df_both)\n",
    "df_both = create_date_features(df_both)\n",
    "# df_both = lag_features(\n",
    "#     df_both, lags=[*range(1, 16), 16, 17, 18, 19, 20, 21, 22, 30, 31, 90, 180, 364]\n",
    "# )\n",
    "# df_both = roll_mean_features(df_both, [16, 17, 18, 30])\n",
    "df_both = df_both[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2197,
   "id": "240d688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphas = [0.95, 0.9, 0.8, 0.5]\n",
    "# lags =[1, 7,30]\n",
    "# all_df = ewma_features(df_all, alphas, lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2198,
   "id": "aa47c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all[\"store_nbr\"] = df_all[\"store_nbr\"].astype(\"category\")\n",
    "# df_all[\"family\"] = df_all[\"family\"].astype(\"category\")\n",
    "# df_all[\"store_nbr\"] = df_all[\"store_nbr\"].astype(\"category\")\n",
    "# df_all[\"cluster\"] = df_all[\"cluster\"].astype(\"category\")\n",
    "# df_all[\"family\"] = df_all[\"family\"].astype(\"category\")\n",
    "# df_all[\"holiday_type\"] = df_all[\"holiday_type\"].astype(\"category\")\n",
    "# df_all[\"locale\"] = df_all[\"locale\"].astype(\"category\")\n",
    "# df_all[\"description\"] = df_all[\"description\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2199,
   "id": "8b8befa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_both = df_both[df_both['date'] > '2013-12-31']\n",
    "# X = df_both[df_both['date'] <= '2017-08-15'].drop('date', axis=1)\n",
    "# X_test = df_both[df_both['date'] > '2017-08-15'].drop('date', axis=1)\n",
    "# corr = X.select_dtypes(include=['number']).corr()\n",
    "# corr[\"sales\"].sort_values(ascending=False)\n",
    "# y = X['sales']\n",
    "# X = X.drop(['sales'], axis=1)\n",
    "# X_test = X_test.drop(['sales'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2200,
   "id": "1e01f5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBC: start from 2014 to have the preceeding Y-1 ?\n",
    "df_both_filtered = df_both[df_both['date'] > '2013-12-31']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34105f09",
   "metadata": {},
   "source": [
    "### Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2201,
   "id": "63a5cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(df):\n",
    "    \"\"\"Encode categorical features\"\"\"\n",
    "    columns_to_encode = df.select_dtypes(\n",
    "        include=[\"object\", \"category\"]\n",
    "    ).columns.tolist()\n",
    "    encoded_df_train = pd.get_dummies(df, columns=columns_to_encode, drop_first=True)\n",
    "\n",
    "    # replace spaces in df columns for lightxgb model\n",
    "    encoded_df_train.columns = encoded_df_train.columns.str.replace(\" \", \"_\")\n",
    "\n",
    "    return encoded_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2202,
   "id": "fbea1fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both_encoded = encode_features(df_both_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2203,
   "id": "273ed5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_all_encoded[df_all_encoded[\"date\"] <= \"2017-08-15\"].drop(\n",
    "#     [\"sales\", \"date\"], axis=1\n",
    "# )\n",
    "# y = df_all_encoded[df_all_encoded[\"date\"] <= \"2017-08-15\"][\"sales\"]\n",
    "\n",
    "df_train_encoded = df_both_encoded[df_both_encoded[\"date\"] <= \"2017-08-15\"]\n",
    "df_test_encoded = df_both_encoded[df_both_encoded[\"date\"] > \"2017-08-15\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2204,
   "id": "235432c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2205,
   "id": "8722521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true_log, y_pred_log):\n",
    "    # \"\"\"\n",
    "    # Compute Root Mean Squared Logarithmic Error for log-transformed targets.\n",
    "    # Parameters:\n",
    "    # - y_true_log: Log-transformed actual values\n",
    "    # - y_pred_log: Log-transformed predicted values\n",
    "    # \"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_true_log, y_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c5b310",
   "metadata": {},
   "source": [
    "### Model v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd174012",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2206,
   "id": "23ca63c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">AUTOMOTIVE</th>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    sales  onpromotion\n",
       "store_nbr family     date                             \n",
       "1         AUTOMOTIVE 2013-01-01  0.000000            0\n",
       "                     2013-01-02  1.098612            0"
      ]
     },
     "execution_count": 2206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert field `date` from type datetime64[ns] to period[D]\n",
    "df_train['date'] = df_train.date.dt.to_period('D')\n",
    "\n",
    "# remove 'id'ArithmeticError\n",
    "df_train.drop('id', axis=1, inplace=True)\n",
    "\n",
    "# create index\n",
    "df_train = df_train.set_index([\"store_nbr\", \"family\", \"date\"]).sort_index()\n",
    "\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025a8c59",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2207,
   "id": "e9a4337e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">sales</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">onpromotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th colspan=\"10\" halign=\"left\">1</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <th>AUTOMOTIVE</th>\n",
       "      <th>BABY CARE</th>\n",
       "      <th>BEAUTY</th>\n",
       "      <th>BEVERAGES</th>\n",
       "      <th>BOOKS</th>\n",
       "      <th>BREAD/BAKERY</th>\n",
       "      <th>CELEBRATION</th>\n",
       "      <th>CLEANING</th>\n",
       "      <th>DAIRY</th>\n",
       "      <th>DELI</th>\n",
       "      <th>...</th>\n",
       "      <th>MAGAZINES</th>\n",
       "      <th>MEATS</th>\n",
       "      <th>PERSONAL CARE</th>\n",
       "      <th>PET SUPPLIES</th>\n",
       "      <th>PLAYERS AND ELECTRONICS</th>\n",
       "      <th>POULTRY</th>\n",
       "      <th>PREPARED FOODS</th>\n",
       "      <th>PRODUCE</th>\n",
       "      <th>SCHOOL AND OFFICE SUPPLIES</th>\n",
       "      <th>SEAFOOD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.26892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.122886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.808143</td>\n",
       "      <td>5.932245</td>\n",
       "      <td>3.828207</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 3564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                sales                                                \\\n",
       "store_nbr           1                                                 \n",
       "family     AUTOMOTIVE BABY CARE BEAUTY BEVERAGES BOOKS BREAD/BAKERY   \n",
       "date                                                                  \n",
       "2017-01-01   0.000000       0.0    0.0   0.00000   0.0     0.000000   \n",
       "2017-01-02   1.791759       0.0    0.0   7.26892   0.0     5.122886   \n",
       "\n",
       "                                                      ... onpromotion        \\\n",
       "store_nbr                                             ...           9         \n",
       "family     CELEBRATION  CLEANING     DAIRY      DELI  ...   MAGAZINES MEATS   \n",
       "date                                                  ...                     \n",
       "2017-01-01         0.0  0.000000  0.000000  0.000000  ...           0     0   \n",
       "2017-01-02         0.0  5.808143  5.932245  3.828207  ...           0     0   \n",
       "\n",
       "                                                                       \\\n",
       "store_nbr                                                               \n",
       "family     PERSONAL CARE PET SUPPLIES PLAYERS AND ELECTRONICS POULTRY   \n",
       "date                                                                    \n",
       "2017-01-01             0            0                       0       0   \n",
       "2017-01-02            13            0                       0       2   \n",
       "\n",
       "                                                                      \n",
       "store_nbr                                                             \n",
       "family     PREPARED FOODS PRODUCE SCHOOL AND OFFICE SUPPLIES SEAFOOD  \n",
       "date                                                                  \n",
       "2017-01-01              0       0                          0       0  \n",
       "2017-01-02              1       4                          0       0  \n",
       "\n",
       "[2 rows x 3564 columns]"
      ]
     },
     "execution_count": 2207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1) Unstack converts levels of a multi-index into column headers, transforming the\n",
    "data from a long to a wide format.\n",
    "2) if the index is a datetime or period index, you can use .loc[] with a string\n",
    "that representsa date or a part of a date (like just the year) to filter the data.\n",
    "\"\"\"\n",
    "y = df_train.unstack(['store_nbr', 'family']).loc[\"2017\"]\n",
    "y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2208,
   "id": "9b130132",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create seasonal features using DeterministicProcess. In this case, 2 seasonal features:\n",
    "1) Weekly -> seasonal=True\n",
    "2) Monthly -> CalendarFourier\n",
    "\"\"\"\n",
    "from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n",
    "\n",
    "fourier = CalendarFourier(\n",
    "    freq=\"M\", order=3\n",
    ")  # 3 sin/cos pairs for \"M\"onthly seasonality\n",
    "\n",
    "dp = DeterministicProcess(\n",
    "    index=y.index,\n",
    "    constant=False,  # dummy feature for bias (y-intercept)\n",
    "    order=5,  # 5th degree polynomial trend\n",
    "    seasonal=True,  # weekly seasonality (indicators), because date is at day level\n",
    "    additional_terms=[fourier],  # monthly seasonality (fourier)\n",
    "    drop=True,  # drop terms to avoid collinearity\n",
    ")\n",
    "\n",
    "X = dp.in_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2209,
   "id": "059e46a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trend</th>\n",
       "      <th>trend_squared</th>\n",
       "      <th>trend_cubed</th>\n",
       "      <th>trend**4</th>\n",
       "      <th>trend**5</th>\n",
       "      <th>s(1,7)</th>\n",
       "      <th>s(2,7)</th>\n",
       "      <th>s(3,7)</th>\n",
       "      <th>s(4,7)</th>\n",
       "      <th>s(5,7)</th>\n",
       "      <th>s(6,7)</th>\n",
       "      <th>s(7,7)</th>\n",
       "      <th>sin(1,freq=M)</th>\n",
       "      <th>cos(1,freq=M)</th>\n",
       "      <th>sin(2,freq=M)</th>\n",
       "      <th>cos(2,freq=M)</th>\n",
       "      <th>sin(3,freq=M)</th>\n",
       "      <th>cos(3,freq=M)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.571268</td>\n",
       "      <td>0.820763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            trend  trend_squared  trend_cubed  trend**4  trend**5  s(1,7)  \\\n",
       "date                                                                        \n",
       "2017-01-01    1.0            1.0          1.0       1.0       1.0     1.0   \n",
       "2017-01-02    2.0            4.0          8.0      16.0      32.0     0.0   \n",
       "\n",
       "            s(2,7)  s(3,7)  s(4,7)  s(5,7)  s(6,7)  s(7,7)  sin(1,freq=M)  \\\n",
       "date                                                                        \n",
       "2017-01-01     0.0     0.0     0.0     0.0     0.0     0.0       0.000000   \n",
       "2017-01-02     1.0     0.0     0.0     0.0     0.0     0.0       0.201299   \n",
       "\n",
       "            cos(1,freq=M)  sin(2,freq=M)  cos(2,freq=M)  sin(3,freq=M)  \\\n",
       "date                                                                     \n",
       "2017-01-01        1.00000       0.000000       1.000000       0.000000   \n",
       "2017-01-02        0.97953       0.394356       0.918958       0.571268   \n",
       "\n",
       "            cos(3,freq=M)  \n",
       "date                       \n",
       "2017-01-01       1.000000  \n",
       "2017-01-02       0.820763  "
      ]
     },
     "execution_count": 2209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2220,
   "id": "7cd88b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trend</th>\n",
       "      <th>trend_squared</th>\n",
       "      <th>trend_cubed</th>\n",
       "      <th>trend**4</th>\n",
       "      <th>trend**5</th>\n",
       "      <th>s(1,7)</th>\n",
       "      <th>s(2,7)</th>\n",
       "      <th>s(3,7)</th>\n",
       "      <th>s(4,7)</th>\n",
       "      <th>s(5,7)</th>\n",
       "      <th>...</th>\n",
       "      <th>sin(2,freq=M)</th>\n",
       "      <th>cos(2,freq=M)</th>\n",
       "      <th>sin(3,freq=M)</th>\n",
       "      <th>cos(3,freq=M)</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>year</th>\n",
       "      <th>new_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.571268</td>\n",
       "      <td>0.820763</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.724793</td>\n",
       "      <td>0.688967</td>\n",
       "      <td>0.937752</td>\n",
       "      <td>0.347305</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            trend  trend_squared  trend_cubed  trend**4  trend**5  s(1,7)  \\\n",
       "date                                                                        \n",
       "2017-01-01    1.0            1.0          1.0       1.0       1.0     1.0   \n",
       "2017-01-02    2.0            4.0          8.0      16.0      32.0     0.0   \n",
       "2017-01-03    3.0            9.0         27.0      81.0     243.0     0.0   \n",
       "\n",
       "            s(2,7)  s(3,7)  s(4,7)  s(5,7)  ...  sin(2,freq=M)  cos(2,freq=M)  \\\n",
       "date                                        ...                                 \n",
       "2017-01-01     0.0     0.0     0.0     0.0  ...       0.000000       1.000000   \n",
       "2017-01-02     1.0     0.0     0.0     0.0  ...       0.394356       0.918958   \n",
       "2017-01-03     0.0     1.0     0.0     0.0  ...       0.724793       0.688967   \n",
       "\n",
       "            sin(3,freq=M)  cos(3,freq=M)  month  day_of_month  day_of_year  \\\n",
       "date                                                                         \n",
       "2017-01-01       0.000000       1.000000      1             1            1   \n",
       "2017-01-02       0.571268       0.820763      1             2            2   \n",
       "2017-01-03       0.937752       0.347305      1             3            3   \n",
       "\n",
       "            day_of_week  year  new_year  \n",
       "date                                     \n",
       "2017-01-01            6  2017      True  \n",
       "2017-01-02            0  2017     False  \n",
       "2017-01-03            1  2017     False  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 2220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = create_date_features2(X)\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8d5336",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2211,
   "id": "13f00e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create date features in df_train\n",
    "# df_train = create_date_features_from_index(df_train)\n",
    "\n",
    "# # Ensure df_train is indexed by 'date' to match X\n",
    "# df_train_reset = df_train.reset_index().set_index('date')\n",
    "\n",
    "# # Merge X with the modified df_train\n",
    "# X = X.merge(\n",
    "#     df_train_reset[\n",
    "#         [\"month\", \"day_of_month\", \"day_of_year\", \"week_of_year\", \"day_of_week\", \"year\"]\n",
    "#     ],\n",
    "#     left_index=True, \n",
    "#     right_index=True,\n",
    "#     how=\"left\"\n",
    "# )\n",
    "\n",
    "# # Check for NaNs after merging\n",
    "# print(\"NaNs in X after merge:\", X.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2212,
   "id": "8cb73533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "PeriodIndex: 227 entries, 2017-01-01 to 2017-08-15\n",
      "Freq: D\n",
      "Columns: 3564 entries, ('sales', '1', 'AUTOMOTIVE') to ('onpromotion', '9', 'SEAFOOD')\n",
      "dtypes: float32(1782), uint32(1782)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca64463",
   "metadata": {},
   "source": [
    "### Split Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2213,
   "id": "09d70271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2214,
   "id": "1058e2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "transformerL = RobustScaler().fit(X_train)\n",
    "\n",
    "X_test = transformerL.transform(X_test)\n",
    "X_train = transformerL.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2215,
   "id": "761fe24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def evaluate_models(regressors, X, y):\n",
    "    results = []\n",
    "    for regressor in regressors:\n",
    "        y_pred = regressor.predict(X)\n",
    "        # TODO: shouldn't happen, but...\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        mae = mean_absolute_error(y, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "        results.append(\n",
    "            {\n",
    "                \"Model\": type(regressor).__name__,\n",
    "                \"MAE\": mae,\n",
    "                \"RMSE\": rmse,\n",
    "            }\n",
    "        )\n",
    "    sorted_results = sorted(results, key=lambda x: x[\"RMSE\"], reverse=False)\n",
    "    print(\n",
    "        f\"{'Model':<25} {'RMSE':<11} {'MAE':<8}\"\n",
    "    )\n",
    "    print(\"-\" * 72)\n",
    "    for result in sorted_results:\n",
    "        metrics = f\"{result['RMSE']:<11.5f} {result['MAE']:<8.2f}\"\n",
    "        print(f\"{result['Model']:<25} {metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172bb618",
   "metadata": {},
   "source": [
    "### Lasso & Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2216,
   "id": "fde1ac55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wint3rmute/Gro/datascilabs/vtensorflow/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn import metrics\n",
    "\n",
    "lasso = Lasso(alpha=1, fit_intercept=True, max_iter=7000).fit(X_train, y_train)\n",
    "\n",
    "ridge = Ridge(alpha=0.4, fit_intercept=True, max_iter=7000).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2217,
   "id": "b3e05d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                     RMSE        MAE     \n",
      "------------------------------------------------------------------------\n",
      "Ridge                     3.21603     1.05    \n",
      "Lasso                     3.67274     1.34    \n"
     ]
    }
   ],
   "source": [
    "models = [ridge, lasso]\n",
    "evaluate_models(models, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9dc4e4",
   "metadata": {},
   "source": [
    "Model                     RMSE        MAE     \n",
    "------------------------------------------------------------------------\n",
    "Ridge                     3.23429     1.06    \n",
    "Lasso                     3.67253     1.34   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2218,
   "id": "3133500f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBased on your description, df_test has 28,512 records, spanning dates from 2017-08-16 to 2017-08-31,\\nwith approximately 1,782 records per day. This structure suggests that for each day, there are 1,782\\ncombinations of 'store_nbr' and 'family' products. Given that there are 16 days in your test date range,\\nthis aligns with the total record count (16 days * 1,782 records/day = 28,512 records).\\n\""
      ]
     },
     "execution_count": 2218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Based on your description, df_test has 28,512 records, spanning dates from 2017-08-16 to 2017-08-31,\n",
    "with approximately 1,782 records per day. This structure suggests that for each day, there are 1,782\n",
    "combinations of 'store_nbr' and 'family' products. Given that there are 16 days in your test date range,\n",
    "this aligns with the total record count (16 days * 1,782 records/day = 28,512 records).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2219,
   "id": "69d0fa43",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- NewYear\nFeature names seen at fit time, yet now missing:\n- day_of_month\n- day_of_week\n- day_of_year\n- month\n- new_year\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2219], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNewYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (X_test\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mdayofyear \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m X_test_copy \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(X_test)\n\u001b[0;32m---> 12\u001b[0m X_test \u001b[38;5;241m=\u001b[39m \u001b[43mtransformerL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m predictionL \u001b[38;5;241m=\u001b[39m lasso\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     15\u001b[0m predictionL[predictionL \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Gro/datascilabs/vtensorflow/lib/python3.11/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/Gro/datascilabs/vtensorflow/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:1594\u001b[0m, in \u001b[0;36mRobustScaler.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Center and scale the data.\u001b[39;00m\n\u001b[1;32m   1582\u001b[0m \n\u001b[1;32m   1583\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[38;5;124;03m    Transformed array.\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1593\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1594\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1596\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m   1604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_scaling:\n",
      "File \u001b[0;32m~/Gro/datascilabs/vtensorflow/lib/python3.11/site-packages/sklearn/base.py:580\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    511\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    517\u001b[0m ):\n\u001b[1;32m    518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \n\u001b[1;32m    520\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    583\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    586\u001b[0m         )\n",
      "File \u001b[0;32m~/Gro/datascilabs/vtensorflow/lib/python3.11/site-packages/sklearn/base.py:507\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    503\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n\u001b[0;32m--> 507\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- NewYear\nFeature names seen at fit time, yet now missing:\n- day_of_month\n- day_of_week\n- day_of_year\n- month\n- new_year\n- ...\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "df_test['date'] = df_test.date.dt.to_period('D')\n",
    "df_test = df_test.set_index(['store_nbr', 'family', 'date']).sort_index()\n",
    "\n",
    "X_test = dp.out_of_sample(steps=16)\n",
    "X_test.index.name = 'date'\n",
    "X_test['NewYear'] = (X_test.index.dayofyear == 1)\n",
    "\n",
    "X_test_copy = copy.deepcopy(X_test)\n",
    "\n",
    "X_test = transformerL.transform(X_test)\n",
    "\n",
    "predictionL = lasso.predict(X_test)\n",
    "predictionL[predictionL < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f20f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submit = pd.DataFrame(np.expm1(predictionL), index=X_test_copy.index, columns=y.columns)\n",
    "# y_submit = pd.DataFrame(predictionL, index=X_test_copy.index, columns=y.columns)\n",
    "y_submit = y_submit.stack(['store_nbr', 'family'])\n",
    "y_submit = y_submit.join(df_test.id).reindex(columns=['id', 'sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e0d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2017-08-16</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>AUTOMOTIVE</th>\n",
       "      <td>3000888</td>\n",
       "      <td>3.283707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BABY CARE</th>\n",
       "      <td>3000889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEAUTY</th>\n",
       "      <td>3000890</td>\n",
       "      <td>2.689846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEVERAGES</th>\n",
       "      <td>3000891</td>\n",
       "      <td>2004.868932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOOKS</th>\n",
       "      <td>3000892</td>\n",
       "      <td>0.320290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2017-08-31</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">9</th>\n",
       "      <th>POULTRY</th>\n",
       "      <td>3029395</td>\n",
       "      <td>418.607620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PREPARED FOODS</th>\n",
       "      <td>3029396</td>\n",
       "      <td>117.379339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRODUCE</th>\n",
       "      <td>3029397</td>\n",
       "      <td>1579.561665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCHOOL AND OFFICE SUPPLIES</th>\n",
       "      <td>3029398</td>\n",
       "      <td>3.194469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEAFOOD</th>\n",
       "      <td>3029399</td>\n",
       "      <td>16.123541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28512 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      id        sales\n",
       "date       store_nbr family                                          \n",
       "2017-08-16 1         AUTOMOTIVE                  3000888     3.283707\n",
       "                     BABY CARE                   3000889     0.000000\n",
       "                     BEAUTY                      3000890     2.689846\n",
       "                     BEVERAGES                   3000891  2004.868932\n",
       "                     BOOKS                       3000892     0.320290\n",
       "...                                                  ...          ...\n",
       "2017-08-31 9         POULTRY                     3029395   418.607620\n",
       "                     PREPARED FOODS              3029396   117.379339\n",
       "                     PRODUCE                     3029397  1579.561665\n",
       "                     SCHOOL AND OFFICE SUPPLIES  3029398     3.194469\n",
       "                     SEAFOOD                     3029399    16.123541\n",
       "\n",
       "[28512 rows x 2 columns]"
      ]
     },
     "execution_count": 1353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7665bcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_submit.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689579bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=13)\n",
    "\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# transformerKERAS = RobustScaler().fit(X_train)\n",
    "\n",
    "# X_val = transformerKERAS.transform(X_val)\n",
    "# X_train = transformerKERAS.transform(X_train)\n",
    "\n",
    "# from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=20, min_lr=0.000001, verbose=1, mode='min')\n",
    "\n",
    "# def create_model():\n",
    "\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(units=500, activation='relu', input_dim=19))\n",
    "#     model.add(Dense(units=2000, activation='relu'))\n",
    "#     model.add(Dense(units=1500, activation='relu'))\n",
    "#     model.add(Dense(units=1782, activation='swish'))\n",
    "\n",
    "#     model.compile(loss='mae', optimizer='adam')\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# model = create_model()\n",
    "# model.fit(X_train, y_train, epochs=5000, batch_size=2000, validation_data=(X_val, y_val),callbacks=[reduce_lr])\n",
    "\n",
    "# y_pred1 = model.predict(X_val)\n",
    "# #print(model1.score(X_val, y_val))\n",
    "\n",
    "# y_pred1[y_pred1 < 0] = 0\n",
    "\n",
    "# print('Mean Absolute Error:', metrics.mean_absolute_error(y_val, y_pred1))\n",
    "# print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val, y_pred1)))\n",
    "\n",
    "# print('======')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a5f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
