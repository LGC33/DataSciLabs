{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Transformation\n",
    "\n",
    "The code in this section is responsible for loading, processing, and transforming the data sets for USDT, USDC, and DAI. It includes functions for reading the transaction data, filtering out exchange-related transactions, and aggregating the data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cex = pd.read_csv('./data/cex.csv')\n",
    "USDC = 'USDC'\n",
    "USDT = 'USDT'\n",
    "DAI = 'DAI'\n",
    "\n",
    "def load_files(stablecoin_name: str):\n",
    "    # Merge datasets\n",
    "    df = pd.DataFrame()\n",
    "    for month in range(1, 11): #until 11 for October'23\n",
    "        file_name = f'{stablecoin_name}_2023.{month:02d}-.csv'\n",
    "        current_df = pd.read_csv(f'../data/2023/{stablecoin_name}/{file_name}')\n",
    "        df = pd.concat([df, current_df], ignore_index=True)\n",
    "    print(f'✅ {stablecoin_name} files successfully loaded.')\n",
    "    return df\n",
    "\n",
    "def transform_data(df, stablecoin_name: str, kyc: bool):\n",
    "    # Create a mask for CEX 'from' addresses and exclude those rows\n",
    "    from_cex_mask = df['from'].isin(cex['address'])\n",
    "    df_filtered = df[~from_cex_mask]\n",
    "\n",
    "    # Depending on the KYC flag, include or exclude 'to' CEX transactions\n",
    "    if kyc:\n",
    "        # For KYC data, include only transactions TO CEX Proxy addresses\n",
    "        df_all = df_filtered[df_filtered['to'].isin(cex['address'])]\n",
    "    else:\n",
    "        # For non-KYC data, exclude transactions TO CEX Proxy addresses\n",
    "        # but include txn from EOA to CEX User addresses\n",
    "        df_all = df_filtered[~df_filtered['to'].isin(cex['address'])]\n",
    "\n",
    "    # Filter for retail transactions (value between 1 and 10000)\n",
    "    retail_mask = df_all['value'].between(1, 10000)\n",
    "    df_retail = df_all[retail_mask]\n",
    "\n",
    "    # Group by 'date' and perform the aggregations\n",
    "    agg_df = df_all.groupby('date')['value'].agg(['sum']).reset_index()\n",
    "    retail_agg_df = df_retail.groupby('date')['value'].agg(['sum']).reset_index()\n",
    "\n",
    "    # Count unique 'from' addresses\n",
    "    wallets = df_all.groupby('date')['from'].nunique().rename('all_wallets' if not kyc else 'kyc_wallets')\n",
    "    retail_wallets = df_retail.groupby('date')['from'].nunique().rename('retail_wallets' if not kyc else 'kyc_retail_wallets')\n",
    "\n",
    "    # Merge the aggregated data with the unique wallets count\n",
    "    df_merged = pd.merge(wallets, agg_df, on='date', how='left')\n",
    "    df_merged = pd.merge(df_merged, retail_wallets, on='date', how='left')\n",
    "    df_merged = pd.merge(df_merged, retail_agg_df, on='date', how='left', suffixes=('', '_retail'))\n",
    "\n",
    "    all_vol = 'all_vol' if not kyc else 'kyc_vol'\n",
    "    retail_vol = 'retail_vol' if not kyc else 'kyc_retail_vol'\n",
    "\n",
    "    # Rename columns\n",
    "    df_merged.rename(columns={'sum': all_vol, 'sum_retail': retail_vol}, inplace=True)\n",
    "\n",
    "    # Add asset type\n",
    "    df_merged['asset'] = stablecoin_name\n",
    "\n",
    "    # Format the date as 'YYYY-MM'\n",
    "    df_merged['date'] = pd.to_datetime(df_merged['date']).dt.to_period('M')\n",
    "\n",
    "    print(f'✅ {stablecoin_name} {'KYC' if kyc else ''} files successfully transformed.')\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "def save_data(df, file_name: str):\n",
    "    df.to_csv(f\"./data/{file_name}.csv\", index=False)\n",
    "    print(f'✅ File `{file_name}` successfully saved.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ USDT files successfully loaded.\n",
      "✅ USDC files successfully loaded.\n",
      "✅ DAI files successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load raw data\n",
    "df_usdt = load_files(USDT)\n",
    "df_usdc = load_files(USDC)\n",
    "df_dai = load_files(DAI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ USDT  files successfully transformed.\n",
      "✅ USDC  files successfully transformed.\n",
      "✅ DAI  files successfully transformed.\n",
      "✅ USDT KYC files successfully transformed.\n",
      "✅ USDC KYC files successfully transformed.\n",
      "✅ DAI KYC files successfully transformed.\n"
     ]
    }
   ],
   "source": [
    "# Transform data\n",
    "df_usdt_unique = transform_data(df_usdt, USDT, False)\n",
    "df_usdc_unique = transform_data(df_usdc, USDC, False)\n",
    "df_dai_unique = transform_data(df_dai, DAI, False)\n",
    "df_usdt_unique_kyc = transform_data(df_usdt, USDT, True)\n",
    "df_usdc_unique_kyc = transform_data(df_usdc, USDC, True)\n",
    "df_dai_unique_kyc = transform_data(df_dai, DAI, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File `df_usdt_unique` successfully saved.\n",
      "✅ File `df_usdc_unique` successfully saved.\n",
      "✅ File `df_dai_unique` successfully saved.\n",
      "✅ File `df_usdt_unique_kyc` successfully saved.\n",
      "✅ File `df_usdc_unique_kyc` successfully saved.\n",
      "✅ File `df_dai_unique_kyc` successfully saved.\n"
     ]
    }
   ],
   "source": [
    "# Save DataFrames into csv files\n",
    "save_data(df_usdt_unique, \"df_usdt_unique\")\n",
    "save_data(df_usdc_unique, \"df_usdc_unique\")\n",
    "save_data(df_dai_unique, \"df_dai_unique\")\n",
    "save_data(df_usdt_unique_kyc, \"df_usdt_unique_kyc\")\n",
    "save_data(df_usdc_unique_kyc, \"df_usdc_unique_kyc\")\n",
    "save_data(df_dai_unique_kyc, \"df_dai_unique_kyc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
