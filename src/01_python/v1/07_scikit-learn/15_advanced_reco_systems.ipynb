{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-Based Filtering: \n",
    "Recommends items based on the attributes of the items and a profile of the user’s preferences. These algorithms try to recommend items that are similar to those that a user liked in the past. The similarity of items is determined based on features associated with the compared items.\n",
    "\n",
    "E.g.: if a user has liked movies from a particular genre or director in the past, the system will recommend movies from those or similar genres or directors. The recommendations are based on item properties like description, category, actors, directors, etc.\n",
    "\n",
    "Content-based methods are limited by the amount of knowledge they have about an item. They can only make recommendations based on available item attributes, and they might not be able to capture the quality of the content without user ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering:\n",
    "\n",
    "Recommends items by identifying patterns in the preferences of multiple users. This approach doesn't require information about the items themselves, rather it operates purely on the user-item interactions data. There are two main subtypes:\n",
    "\n",
    "- **Memory-Based**: involves using the entire user-item dataset to generate recommendations:\n",
    "  - **User-Item Filtering**: finds users that are similar to the target user (based on similarity in their ratings) and recommends items that these similar users liked. For instance, if users A and B have similar ratings for the same movies, then movies liked by user A that user B has not seen yet might be recommended to user B.\n",
    "  - **Item-Item Filtering**: recommends items that are similar to that item. For example, if a user liked a particular book, similar books (based on ratings by all users) will be recommended.\n",
    "\n",
    ".\n",
    "- **Model-Based**: involves building predictive models. These models predict user ratings for items based on past ratings:\n",
    "  - **Matrix Factorization**: Such as Singular Value Decomposition (SVD). The user-item interactions matrix is decomposed into the product of two lower dimensionality rectangular matrices. This method helps in reducing the dimensionality of the dataset and filling in the missing values in the matrix.\n",
    "  - **Machine Learning Algorithms**: Various machine learning algorithms like neural networks, clustering, and regression models are used to predict user ratings.\n",
    "\n",
    "Memory-based methods are easy to implement and produce reasonable recommendation quality. However, they are not scalable and are computationally expensive as they require computing the similarities between all user pairs or all item pairs.\n",
    "\n",
    "Model-based methods are scalable and can deal with higher sparsity level than memory-based models, but they are more complex and require a learning process to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "1b8fd1e7-2a7f-48ea-9bf0-2e4aa8d36cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>880473582</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>891271545</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>888552084</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>879362124</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp             title\n",
       "0        0       50       5  881250949  Star Wars (1977)\n",
       "1      290       50       5  880473582  Star Wars (1977)\n",
       "2       79       50       4  891271545  Star Wars (1977)\n",
       "3        2       50       5  888552084  Star Wars (1977)\n",
       "4        8       50       5  879362124  Star Wars (1977)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = [\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    "df = pd.read_csv(\"./filez/Movie_u.data\", sep=\"\\t\", names=col_names)  # tab separated\n",
    "\n",
    "movie_titles = pd.read_csv(\"./filez/Movie_Id_Titles\")\n",
    "df = pd.merge(df, movie_titles, on=\"item_id\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Users:  944\n",
      "Num of Movies: 1682\n"
     ]
    }
   ],
   "source": [
    "n_users = df.user_id.nunique()\n",
    "n_items = df.item_id.nunique()\n",
    "\n",
    "print(\"Num of Users:  \" + str(n_users))\n",
    "print(\"Num of Movies: \" + str(n_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\"\n",
    "segment data in just two sets of data:\n",
    "- training matrix: 75% of the ratings\n",
    "- testing matrix: 25% of the ratings\n",
    "\"\"\"\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory-Based Collaborative Filtering\n",
    "* *User-Item Collaborative Filtering*: “Users who are similar to you also liked …”\n",
    "* *Item-Item Collaborative Filtering*: “Users who liked this item also liked …”\n",
    "\n",
    "Both filters require creating a user-item matrix for the entire dataset. Since we have split the data into testing and training we will need to create two ``[944 x 1682]`` matrices (all users by all movies).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two user-item matrices, one for training and another for testing\n",
    "\n",
    "\"\"\"\n",
    "- The for loop iterates over each row (line) in the train_data DataFrame.\n",
    "- line[1] and line[2] are the user ID and item ID, respectively.\n",
    "    The - 1 is there because Python uses zero-based indexing, while user IDs \n",
    "    and item IDs typically start from 1.\n",
    "- line[3] is the rating given by the user to the item.\n",
    "- Each line[1] - 1 and line[2] - 1 combination corresponds to a specific cell\n",
    "    in the matrix, and line[3] is the value assigned to that cell. Essentially,\n",
    "    this step is filling in the user-item matrix with the ratings from the\n",
    "    train dataset.\n",
    "(then same for test dataset)\n",
    "\"\"\"\n",
    "\n",
    "train_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in train_data.itertuples():\n",
    "    train_data_matrix[line[1] - 1, line[2] - 1] = line[3]\n",
    "\n",
    "test_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in test_data.itertuples():\n",
    "    test_data_matrix[line[1] - 1, line[2] - 1] = line[3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "\"\"\"\n",
    "A distance metric commonly used in recommender systems is cosine similarity,\n",
    "where the ratings are seen as vectors in n-dimensional space and the \n",
    "similarity is calculated based on the angle between these vectors.\n",
    "-> The output will range from 0 to 1 since all ratings are positive\n",
    "\"\"\"\n",
    "\n",
    "user_similarity_matrix = pairwise_distances(train_data_matrix, metric=\"cosine\")\n",
    "item_similarity_matrix = pairwise_distances(train_data_matrix.T, metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity between users can be seen as weights that are multiplied by the ratings of a similar user (corrected for the average rating of that user). We need to normalize it so that the ratings stay between 1 and 5 and, as a final step, sum the average ratings for the user that you are trying to predict. \n",
    "\n",
    "The idea here is that some users may tend always to give high or low ratings to all movies. The relative difference in the ratings that these users give is more important than the absolute values. E.g.: suppose, user *k* gives 4 stars to his favourite movies and 3 stars to all other good movies. Suppose now that another user *t* rates movies that he/she likes with 5 stars, and the movies he/she fell asleep over with 3 stars. These two users could have a very similar taste but treat the rating system differently. \n",
    "\n",
    "When making a prediction for item-based CF we don't need to correct for users average rating since query user itself is used to do predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, type=\"user\"):\n",
    "    \"\"\"output: The predicted ratings matrix, which has the same dimensions as the input ratings matrix.\"\"\"\n",
    "    if type == \"user\":\n",
    "        # calculates the mean rating for each user (across all items)\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        # calculates the difference between each user's ratings and their mean rating\n",
    "        # use np.newaxis so that mean_user_rating has same format as ratings\n",
    "        ratings_diff = ratings - mean_user_rating[:, np.newaxis]\n",
    "        # - similarity.dot(ratings_diff): This computes the weighted sum of rating deviations\n",
    "        #   for each user, using the similarity matrix: it tries to capture the influence of\n",
    "        #   similar users' preferences.\n",
    "        # - The result is divided by the sum of the absolute values of the user similarities\n",
    "        #   (np.abs(similarity).sum(axis=1)), normalizing the prediction.\n",
    "        # - the mean user rating is added back to adjust the prediction to the appropriate scale.\n",
    "        pred = (\n",
    "            mean_user_rating[:, np.newaxis]\n",
    "            + similarity.dot(ratings_diff)\n",
    "            / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "        )\n",
    "    elif type == \"item\":\n",
    "        # - computes the predicted rating for each item as a weighted average\n",
    "        #   of all other items, weighted by the item similarity scores.\n",
    "        # - the ratings are multiplied (dot product) by the item similarity matrix.\n",
    "        # - then, it's normalized by dividing by the sum of the absolute values\n",
    "        #   of the item similarities (np.abs(similarity).sum(axis=1)).\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_prediction = predict(train_data_matrix, item_similarity_matrix, type=\"item\")\n",
    "user_prediction = predict(train_data_matrix, user_similarity_matrix, type=\"user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many evaluation metrics but one of the most popular metric used to evaluate accuracy of predicted ratings is *Root Mean Squared Error (RMSE)*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "def rmse(prediction, ground_truth):\n",
    "    \"\"\"\n",
    "    Since we only want to consider predicted ratings that are in the\n",
    "    test dataset, we filter out all other elements in the prediction\n",
    "    matrix with `prediction[ground_truth.nonzero()]`.\n",
    "    \"\"\"\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE: 3.124570497835974\n",
      "Item-based CF RMSE: 3.4535601310961703\n"
     ]
    }
   ],
   "source": [
    "print('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))\n",
    "print('Item-based CF RMSE: ' + str(rmse(item_prediction, test_data_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Root Mean Square Error (RMSE)**\n",
    "- RMSE is a standard way to measure the error of a model in predicting quantitative data.\n",
    "- It represents the square root of the second sample moment of the differences between predicted values and observed values or the quadratic mean of these differences.\n",
    "- In simpler terms, RMSE tells you how concentrated the data is around the line of best fit. Lower values of RMSE indicate a better fit.\n",
    "\n",
    "\n",
    "**Interpreting the Output**\n",
    "- **User-based CF RMSE**: `3.1272613401638307`: This is the RMSE for the user-based collaborative filtering model. It indicates, on average, the magnitude of error between the model's predictions and the actual ratings in the test data set. A value of 3.12 suggests that the predictions are, on average, about 3.12 units away from the actual user ratings.\n",
    "- **Item-based CF RMSE**: `3.4551423218319646`: This is the RMSE for the item-based collaborative filtering model. Similar to the user-based RMSE, it measures the average error in the item-based predictions. The value of 3.45 indicates a slightly higher error in prediction compared to the user-based model.\n",
    "\n",
    "\n",
    "**Why This Matters**\n",
    "\n",
    "- By comparing the RMSE of different models, you can assess which model performs better in terms of accuracy. In this case, the user-based model has a lower RMSE, suggesting it may be more accurate for your dataset.\n",
    "- However, it's important to note that RMSE is just one metric, and it should be considered alongside other factors like the nature of the data, the context of the problem, and the specific use case of the recommendations.\n",
    "- It's also worth noting that RMSE values are relative and should be interpreted within the context of your specific dataset and application. For instance, an RMSE of 3.12 might be acceptable in one context but too high in another, depending on how ratings are scaled and the importance of precision in your application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory-based algorithms are easy to implement and produce reasonable prediction quality.\n",
    "\n",
    "The drawback of memory-based CF is that it doesn't scale to real-world scenarios and doesn't address the well-known cold-start problem, that is when new user or new item enters the system.\n",
    "\n",
    "Model-based CF methods are scalable and can deal with higher sparsity level than memory-based models, but also suffer when new users or items that don't have any ratings enter the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_title(user_id: int, type: str):\n",
    "    # Step 1: Choose method\n",
    "    pred = user_prediction[user_id] if type == \"user\" else item_prediction[user_id]\n",
    "\n",
    "    # Step 2: Get predicted ratings for this user\n",
    "    predicted_ratings_df = pd.DataFrame(pred, columns=[\"predicted_rating\"])\n",
    "\n",
    "    # Step 3: Filter out items the user has already rated\n",
    "    # user_rated_items = df[df[\"user_id\"] == user_id][\"item_id\"].values\n",
    "    # predicted_ratings_df = predicted_ratings_df[\n",
    "    #     ~predicted_ratings_df.index.isin(user_rated_items)\n",
    "    # ]\n",
    "    \n",
    "\n",
    "    # Step 4: Select the top 5 titles\n",
    "    top_5_items = (\n",
    "        predicted_ratings_df.sort_values(by=\"predicted_rating\", ascending=False)\n",
    "        .head(5)\n",
    "        .index\n",
    "    )\n",
    "\n",
    "    # Step 5: Retrieve the titles\n",
    "    top_5_titles = df[df[\"item_id\"].isin(top_5_items)][\"title\"].unique().tolist()\n",
    "\n",
    "    # Step 6: Print the top 5 titles\n",
    "    print(f\"Top 5 recommended titles for user {user_id} based on {type} prediction:\\n\")\n",
    "    for item in top_5_titles:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended titles for user 70 based on user prediction:\n",
      "\n",
      "- Men in Black (1997)\n",
      "- I.Q. (1994)\n",
      "- Snow White and the Seven Dwarfs (1937)\n",
      "- Apocalypse Now (1979)\n"
     ]
    }
   ],
   "source": [
    "recommend_title(user_id=70, type='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended titles for user 70 based on item prediction:\n",
      "\n",
      "- Tetsuo II: Body Hammer (1992)\n",
      "- Innocent Sleep, The (1995)\n",
      "- Broken English (1996)\n",
      "- Underneath, The (1995)\n",
      "- Death in the Garden (Mort en ce jardin, La) (1956)\n"
     ]
    }
   ],
   "source": [
    "recommend_title(user_id=70, type='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18017</th>\n",
       "      <td>70</td>\n",
       "      <td>174</td>\n",
       "      <td>5</td>\n",
       "      <td>884065782</td>\n",
       "      <td>Raiders of the Lost Ark (1981)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>70</td>\n",
       "      <td>423</td>\n",
       "      <td>5</td>\n",
       "      <td>884066910</td>\n",
       "      <td>E.T. the Extra-Terrestrial (1982)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29617</th>\n",
       "      <td>70</td>\n",
       "      <td>228</td>\n",
       "      <td>5</td>\n",
       "      <td>884064269</td>\n",
       "      <td>Star Trek: The Wrath of Khan (1982)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22539</th>\n",
       "      <td>70</td>\n",
       "      <td>419</td>\n",
       "      <td>5</td>\n",
       "      <td>884065035</td>\n",
       "      <td>Mary Poppins (1964)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28157</th>\n",
       "      <td>70</td>\n",
       "      <td>483</td>\n",
       "      <td>5</td>\n",
       "      <td>884064444</td>\n",
       "      <td>Casablanca (1942)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68363</th>\n",
       "      <td>70</td>\n",
       "      <td>511</td>\n",
       "      <td>5</td>\n",
       "      <td>884067855</td>\n",
       "      <td>Lawrence of Arabia (1962)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58976</th>\n",
       "      <td>70</td>\n",
       "      <td>588</td>\n",
       "      <td>5</td>\n",
       "      <td>884065528</td>\n",
       "      <td>Beauty and the Beast (1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>70</td>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "      <td>884064217</td>\n",
       "      <td>Empire Strikes Back, The (1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25448</th>\n",
       "      <td>70</td>\n",
       "      <td>298</td>\n",
       "      <td>5</td>\n",
       "      <td>884064134</td>\n",
       "      <td>Face/Off (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10271</th>\n",
       "      <td>70</td>\n",
       "      <td>143</td>\n",
       "      <td>5</td>\n",
       "      <td>884149431</td>\n",
       "      <td>Sound of Music, The (1965)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49693</th>\n",
       "      <td>70</td>\n",
       "      <td>404</td>\n",
       "      <td>4</td>\n",
       "      <td>884149622</td>\n",
       "      <td>Pinocchio (1940)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48941</th>\n",
       "      <td>70</td>\n",
       "      <td>217</td>\n",
       "      <td>4</td>\n",
       "      <td>884151119</td>\n",
       "      <td>Bram Stoker's Dracula (1992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47243</th>\n",
       "      <td>70</td>\n",
       "      <td>173</td>\n",
       "      <td>4</td>\n",
       "      <td>884149452</td>\n",
       "      <td>Princess Bride, The (1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45940</th>\n",
       "      <td>70</td>\n",
       "      <td>176</td>\n",
       "      <td>4</td>\n",
       "      <td>884066573</td>\n",
       "      <td>Aliens (1986)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>884064188</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  rating  timestamp  \\\n",
       "18017       70      174       5  884065782   \n",
       "10397       70      423       5  884066910   \n",
       "29617       70      228       5  884064269   \n",
       "22539       70      419       5  884065035   \n",
       "28157       70      483       5  884064444   \n",
       "68363       70      511       5  884067855   \n",
       "58976       70      588       5  884065528   \n",
       "944         70      172       5  884064217   \n",
       "25448       70      298       5  884064134   \n",
       "10271       70      143       5  884149431   \n",
       "49693       70      404       4  884149622   \n",
       "48941       70      217       4  884151119   \n",
       "47243       70      173       4  884149452   \n",
       "45940       70      176       4  884066573   \n",
       "14          70       50       4  884064188   \n",
       "\n",
       "                                     title  \n",
       "18017       Raiders of the Lost Ark (1981)  \n",
       "10397    E.T. the Extra-Terrestrial (1982)  \n",
       "29617  Star Trek: The Wrath of Khan (1982)  \n",
       "22539                  Mary Poppins (1964)  \n",
       "28157                    Casablanca (1942)  \n",
       "68363            Lawrence of Arabia (1962)  \n",
       "58976          Beauty and the Beast (1991)  \n",
       "944        Empire Strikes Back, The (1980)  \n",
       "25448                      Face/Off (1997)  \n",
       "10271           Sound of Music, The (1965)  \n",
       "49693                     Pinocchio (1940)  \n",
       "48941         Bram Stoker's Dracula (1992)  \n",
       "47243           Princess Bride, The (1987)  \n",
       "45940                        Aliens (1986)  \n",
       "14                        Star Wars (1977)  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['user_id'] == 70].sort_values(by=['rating'], ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Conclusion:\n",
    "    - this method is just not working properly 😅\n",
    "    - recommended items from both methods seem to be quite unrelated between each other and vs. user's most rated films\n",
    "    - alternatively worth trying the SVD method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
