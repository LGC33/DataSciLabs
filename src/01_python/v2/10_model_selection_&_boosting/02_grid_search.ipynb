{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb0a57ec",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "Grid search is a systematic approach to tuning hyperparameters where a model is trained and evaluated exhaustively over a specified range of parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a43c6",
   "metadata": {},
   "source": [
    "### Importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1b8fd1e7-2a7f-48ea-9bf0-2e4aa8d36cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece4fc81",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "88affc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  EstimatedSalary  Purchased\n",
       "0   19            19000          0\n",
       "1   35            20000          0\n",
       "2   26            43000          0\n",
       "3   27            57000          0\n",
       "4   19            76000          0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./filez/Social_Network_Ads.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ab710a",
   "metadata": {},
   "source": [
    "### Splitting the dataset into Train/Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "009b46ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dataset.drop(\"Purchased\", axis=1)\n",
    "y = dataset[\"Purchased\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac295f",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3d504317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c6b10c",
   "metadata": {},
   "source": [
    "### Training the Kernel SVM model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d67a8989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC(kernel=\"rbf\", random_state=0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a95b912",
   "metadata": {},
   "source": [
    "### Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ac231412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) classification_report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95        68\n",
      "           1       0.88      0.91      0.89        32\n",
      "\n",
      "    accuracy                           0.93       100\n",
      "   macro avg       0.92      0.92      0.92       100\n",
      "weighted avg       0.93      0.93      0.93       100\n",
      "\n",
      "2) confusion_matrix:\n",
      "\n",
      " [[64  4]\n",
      " [ 3 29]] \n",
      "\n",
      "3) accuracy_score:\n",
      "\n",
      " 0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "def evaluate_model(classifier):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    print(f\"1) classification_report:\\n\\n\", classification_report(y_test, y_pred))\n",
    "    print(f\"2) confusion_matrix:\\n\\n\", confusion_matrix(y_test, y_pred), \"\\n\")\n",
    "    print(f\"3) accuracy_score:\\n\\n\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "evaluate_model(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55702182",
   "metadata": {},
   "source": [
    "### Applying K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bb3a78c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def show_accuracy():\n",
    "    accuracies = cross_val_score(estimator=classifier, X=X_train, y=y_train, cv=10)\n",
    "    print(f\"Accuracy {accuracies.mean() * 100:,.2f}%\")\n",
    "    print(f\"Standard Deviation: {accuracies.std()*100:,.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "25f9f428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 90.33%\n",
      "Standard Deviation: 6.57%\n"
     ]
    }
   ],
   "source": [
    "show_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4ab0d7",
   "metadata": {},
   "source": [
    "### Applying Grid Search to find the best model and the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7954a4e0",
   "metadata": {},
   "source": [
    "- **C (Regularization parameter)**: tells the SVM optimization how much you want to avoid misclassifying each training example. Larger values of C will choose a smaller-margin hyperplane if that hyperplane does a better job of getting all the training points classified correctly.\n",
    "Additional values: You might try more values around the range you've already set, especially if you notice the best performance is on the edges of your current range. Consider trying smaller increments (e.g., 0.1, 0.2, 0.3) or larger values if overfitting is not an issue.\n",
    "\n",
    "- **gamma (Kernel coefficient for ‘rbf’)**: defines how far the influence of a single training example reaches. Low values mean ‘far’ and high values mean ‘close’.\n",
    "Additional values: Similar to C, you could try more granular values or a wider range if needed. If the best gamma is at one end of your range, extend the range in that direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1ba9f627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy: 91.00%\n",
      "best params: {'C': 0.8, 'gamma': 0.9, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# list of combinations of hyperparameters in two dictionaries to test 2 different kernels,\n",
    "# because the gamma parameter can only be used with the rbf kernel\n",
    "# dict 1: linear kernel\n",
    "# dict 2: rbf kernel\n",
    "\n",
    "ranges = [i/10 for i in range(1, 10)] # from 0.1 to 0.9\n",
    "\n",
    "params = [\n",
    "    {\n",
    "        \"C\": ranges,\n",
    "        \"kernel\": [\"linear\"],\n",
    "    },\n",
    "    {\n",
    "        \"C\": ranges,\n",
    "        \"kernel\": [\"rbf\"],\n",
    "        \"gamma\": ranges,\n",
    "    },\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=classifier, param_grid=params, scoring=\"accuracy\", cv=10, n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X=X_train, y=y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(f'best accuracy: {best_accuracy * 100:,.2f}%')\n",
    "print(f'best params: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4a44e395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 91.00%\n",
      "Standard Deviation: 6.67%\n"
     ]
    }
   ],
   "source": [
    "# Model with the best params:\n",
    "classifier = SVC(kernel=\"rbf\", random_state=0, C=0.8, gamma=0.9)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "show_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77df52e0",
   "metadata": {},
   "source": [
    "**Evaluating the Trade-off**:\n",
    "- Higher Average Accuracy: The second model has a higher average accuracy (91.00% vs. 90.33%). This suggests that, on average, it is slightly better at making correct predictions.\n",
    "- Higher Standard Deviation: The second model also has a slightly higher standard deviation (6.67% vs. 6.57%). This means there's more variability in its performance across different subsets of the data.\n",
    "\n",
    "**Decision Criteria**:\n",
    "- Prioritizing Accuracy: If your primary goal is to achieve the highest possible accuracy, the second model is preferable. The increase in accuracy, though marginal, might be significant depending on the application.\n",
    "- Prioritizing Consistency: If consistency across different datasets or cross-validation folds is more critical, the first model may be more appropriate, as it has a slightly lower standard deviation. However, the difference in standard deviation is very small (0.1 percentage points), so this might not be a decisive factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d83568a",
   "metadata": {},
   "source": [
    "### Accuracy vs. Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e20bb6",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "- **What Is It?**: Accuracy measures how often a model makes the correct prediction. It's like the model's hit rate – how many times it gets things right.\n",
    "- **Example**: Imagine a weather forecasting model. If it predicts rain and it actually rains on 70 out of 100 days when it predicted rain, its accuracy is 70%.\n",
    "\n",
    "#### Consistency (Standard Deviation in Performance)*\n",
    "- **What Is It?**: Consistency here refers to how stable or variable the model's performance is across different situations or datasets. A lower standard deviation in model performance implies greater consistency.\n",
    "- **Example**: Let's say you use the same weather forecasting model in different cities. In City A, its accuracy is 68%; in City B, it's 72%; in City C, it's 69%. The small range in accuracy (68% to 72%) across cities indicates high consistency. Now imagine another scenario where in City A, its accuracy is 50%; in City B, 90%; in City C, 70%. Here, the wide range (50% to 90%) indicates low consistency.\n",
    "\n",
    "#### Simplified Comparison\n",
    "- **Accuracy vs. Consistency**: A model could be highly accurate but not consistent. For example, it might work exceptionally well in certain conditions (e.g., predicting sunny days) but poorly in others (e.g., predicting rainy days), leading to high accuracy but low consistency. Conversely, a model could be consistently good but not the best in terms of accuracy. It might always be somewhat right but rarely perfect.\n",
    "\n",
    "#### Clear Example\n",
    "- **Weather Forecast Model**:\n",
    "  - **High Accuracy, Low Consistency**: A model predicts weather with 95% accuracy during summer but only 55% accuracy during winter. Its overall accuracy might be high, but its performance is inconsistent across seasons.\n",
    "  - **Lower Accuracy, High Consistency**: Another model predicts weather with 75% accuracy year-round, regardless of the season. Its accuracy isn't as high as the first model in summer, but it's more consistent throughout the year.\n",
    "\n",
    "In summary, accuracy tells you how often the model is right, while consistency tells you how stable the model's accuracy is across different conditions or datasets. In real-world applications, the choice between a highly accurate model and a consistently good model often depends on the specific needs and context of the task at hand.\n",
    "\n",
    "(*) In the context of evaluating machine learning models, when we talk about standard deviation, we're typically referring to the variation in the model's performance across different scenarios or datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
