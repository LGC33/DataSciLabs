{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model with Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1b8fd1e7-2a7f-48ea-9bf0-2e4aa8d36cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./filez/iris.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
       "       'petal width (cm)', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns can't have spaces or special characters\n",
    "df.columns = [\n",
    "    \"sepal_length\",\n",
    "    \"sepal_width\",\n",
    "    \"petal_length\",\n",
    "    \"petal_width\",\n",
    "    \"target\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  target\n",
       "0           5.1          3.5           1.4          0.2       0\n",
       "1           4.9          3.0           1.4          0.2       0\n",
       "2           4.7          3.2           1.3          0.2       0"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target must be integer for classification (binary-class)\n",
    "df[\"target\"] = df[\"target\"].apply(int)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features from the target\n",
    "y = df[\"target\"]\n",
    "X = df.drop(\"target\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model with Sequential Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries:\n",
    "- `Sequential`: This is a Keras model that represents a linear stack of layers.\n",
    "- `Dense`: A type of layer that is fully connected, meaning each neuron in this layer is connected to all neurons in the previous layer.\n",
    "- `To_categorical`: A utility function to convert integer labels into a one-hot encoded format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Labels to One-Hot Encoded Format\n",
    "We convert the labels into a format suitable for classification (to_categorical).\n",
    "\n",
    "This makes each label a vector with a 1 in the position of the correct class and 0s elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoded format\n",
    "yc = to_categorical(y, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, yc, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Model\n",
    "Define the structure of the neural network model with Sequential() -> Initializes a linear stack of layers.\n",
    "- `Dense(10, input_dim=4, activation='relu')`: Adds a layer with 10 neurons, `input_dim=4` indicates the number of input features, and `relu` is the activation function.\n",
    "- `Dense(20, activation='relu')`: A hidden layer with 20 neurons.\n",
    "- `Dense(10, activation='relu')`: Another hidden layer with 10 neurons.\n",
    "- `Dense(3, activation='softmax')`: The output layer with 3 neurons (one for each class), using `softmax` to output class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=4, activation=\"relu\"))  # First hidden layer\n",
    "model.add(Dense(20, activation=\"relu\"))  # Second hidden layer\n",
    "model.add(Dense(10, activation=\"relu\"))  # Third hidden layer\n",
    "model.add(Dense(3, activation=\"softmax\"))  # Output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model\n",
    "Configure the model for training by setting the optimizer, loss function, and metrics.\n",
    "- `optimizer='adam'`: Specifies the optimization algorithm; 'adam' is effective for a wide range of problems.\n",
    "- `loss='categorical_crossentropy'`: The loss function for multi-class classification.\n",
    "- `metrics=['accuracy']`: The metric to evaluate during training and testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "- `X_train, y_train`: The training data and labels.\n",
    "- `epochs=50`: The number of times the model will work through the entire training dataset.\n",
    "- `batch_size=10`: The number of samples processed before the model is updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 710us/step - loss: 1.0679 - accuracy: 0.3714\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 674us/step - loss: 1.0078 - accuracy: 0.4381\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 602us/step - loss: 0.9755 - accuracy: 0.3619\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 655us/step - loss: 0.9455 - accuracy: 0.3619\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 636us/step - loss: 0.9151 - accuracy: 0.4000\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 618us/step - loss: 0.8785 - accuracy: 0.5143\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 587us/step - loss: 0.8265 - accuracy: 0.6857\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 606us/step - loss: 0.7498 - accuracy: 0.6667\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 573us/step - loss: 0.6934 - accuracy: 0.6381\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 575us/step - loss: 0.6395 - accuracy: 0.6571\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 502us/step - loss: 0.5928 - accuracy: 0.7619\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 576us/step - loss: 0.5570 - accuracy: 0.8095\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 540us/step - loss: 0.5211 - accuracy: 0.8381\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 569us/step - loss: 0.4932 - accuracy: 0.8857\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 548us/step - loss: 0.4633 - accuracy: 0.9333\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 566us/step - loss: 0.4397 - accuracy: 0.9429\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 538us/step - loss: 0.4183 - accuracy: 0.9143\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 594us/step - loss: 0.3937 - accuracy: 0.9333\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 589us/step - loss: 0.3740 - accuracy: 0.9714\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 560us/step - loss: 0.3612 - accuracy: 0.9619\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 499us/step - loss: 0.3407 - accuracy: 0.9524\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 592us/step - loss: 0.3229 - accuracy: 0.9714\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 495us/step - loss: 0.3085 - accuracy: 0.9714\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 506us/step - loss: 0.2993 - accuracy: 0.9619\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 475us/step - loss: 0.2783 - accuracy: 0.9714\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.2660 - accuracy: 0.9714\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 491us/step - loss: 0.2577 - accuracy: 0.9619\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 527us/step - loss: 0.2457 - accuracy: 0.9714\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 520us/step - loss: 0.2329 - accuracy: 0.9714\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 519us/step - loss: 0.2225 - accuracy: 0.9714\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 475us/step - loss: 0.2131 - accuracy: 0.9714\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 548us/step - loss: 0.2038 - accuracy: 0.9714\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 500us/step - loss: 0.1950 - accuracy: 0.9714\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 489us/step - loss: 0.1909 - accuracy: 0.9714\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 535us/step - loss: 0.1872 - accuracy: 0.9619\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1741 - accuracy: 0.9714\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.9714\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 685us/step - loss: 0.1633 - accuracy: 0.9714\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 461us/step - loss: 0.1628 - accuracy: 0.9619\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 503us/step - loss: 0.1568 - accuracy: 0.9714\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 442us/step - loss: 0.1525 - accuracy: 0.9810\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 574us/step - loss: 0.1509 - accuracy: 0.9714\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 450us/step - loss: 0.1421 - accuracy: 0.9714\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 549us/step - loss: 0.1361 - accuracy: 0.9810\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 460us/step - loss: 0.1334 - accuracy: 0.9714\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 493us/step - loss: 0.1319 - accuracy: 0.9714\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 477us/step - loss: 0.1302 - accuracy: 0.9714\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 477us/step - loss: 0.1227 - accuracy: 0.9810\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 462us/step - loss: 0.1218 - accuracy: 0.9810\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 518us/step - loss: 0.1168 - accuracy: 0.9714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2d1be76d0>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model\n",
    "Assess the model's performance on unseen data and to understand its accuracy and where it might be making errors.\n",
    "- `y_pred` = model.predict(X_test): Uses the trained model to make predictions on the test set.\n",
    "- `tf.argmax(y_pred, axis=1)`: Converts predicted probabilities to class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step\n",
      "[[21  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  2 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       0.85      0.92      0.88        12\n",
      "           2       0.91      0.83      0.87        12\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.92      0.92      0.92        45\n",
      "weighted avg       0.93      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
    "y_test_classes = tf.argmax(y_test, axis=1)\n",
    "\n",
    "print(confusion_matrix(y_test_classes, y_pred_classes))\n",
    "print(classification_report(y_test_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legacy Neural Network Model with DNNClassifier estimator\n",
    "*from TensorFlow v1.x*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/1d/ty_knwmj61b4d3qs091tfglm0000gn/T/tmpnu8oxron\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/1d/ty_knwmj61b4d3qs091tfglm0000gn/T/tmpnu8oxron', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/1d/ty_knwmj61b4d3qs091tfglm0000gn/T/tmpnu8oxron/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 24.127686, step = 0\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 50...\n",
      "INFO:tensorflow:Saving checkpoints for 50 into /var/folders/1d/ty_knwmj61b4d3qs091tfglm0000gn/T/tmpnu8oxron/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 50...\n",
      "INFO:tensorflow:Loss for final step: 4.1767797.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/1d/ty_knwmj61b4d3qs091tfglm0000gn/T/tmpnu8oxron/model.ckpt-50\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[[11  0  0]\n",
      " [ 1 12  6]\n",
      " [ 0  0 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        11\n",
      "           1       1.00      0.63      0.77        19\n",
      "           2       0.71      1.00      0.83        15\n",
      "\n",
      "    accuracy                           0.84        45\n",
      "   macro avg       0.88      0.88      0.85        45\n",
      "weighted avg       0.88      0.84      0.84        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feat_cols = [tf.feature_column.numeric_column(col) for col in X.columns]\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=98)\n",
    "\n",
    "train_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "    x=X_train, y=y_train, batch_size=10, num_epochs=5, shuffle=True\n",
    ")\n",
    "test_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "    x=X_test, y=y_test, batch_size=10, shuffle=False\n",
    ")\n",
    "\n",
    "classifier = tf.compat.v1.estimator.DNNClassifier(\n",
    "    hidden_units=[10, 20, 10], n_classes=3, feature_columns=feat_cols\n",
    ")\n",
    "classifier.train(input_fn=train_input_fn, steps=50)\n",
    "\n",
    "predictions = list(classifier.predict(input_fn=test_input_fn))\n",
    "final_preds = [pred[\"class_ids\"][0] for pred in predictions]\n",
    "\n",
    "print(confusion_matrix(y_test, final_preds))\n",
    "print(classification_report(y_test, final_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
