{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15b9bae",
   "metadata": {},
   "source": [
    "# Regression Template\n",
    "v1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cf900c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "id": "75a53813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26b7192",
   "metadata": {},
   "source": [
    "### Read Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "id": "7aa0892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(df):\n",
    "    \"\"\"\n",
    "    Display the first two and the last two records of a DataFrame\n",
    "    \"\"\"\n",
    "    print(pd.concat([df.head(2), df.tail(2)]))\n",
    "\n",
    "\n",
    "def show_missing_data(df):\n",
    "    \"\"\"\n",
    "    Display number and percentage of missing values in all columns\n",
    "    \"\"\"\n",
    "    total = df.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (\n",
    "        ((df.isnull().sum() / df.isnull().count()) * 100)\n",
    "        .sort_values(ascending=False)\n",
    "        .round(2)\n",
    "    )\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=[\"# missing\", \"% missing\"])\n",
    "    print(missing_data)\n",
    "\n",
    "\n",
    "def show_unique_values(df, fields):\n",
    "    \"\"\"\n",
    "    Show unique values in DataFrame given a list of fields\n",
    "    \"\"\"\n",
    "    for field in fields:\n",
    "        try:\n",
    "            print(f\"{field}: {df[field].unique()}\")\n",
    "        except KeyError:\n",
    "            print(f\"`{field}` not found in DataFrame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1be081",
   "metadata": {},
   "source": [
    "### Write Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "id": "3b90320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "def update_null_values(df, fields, strategy, fill_value=np.nan):\n",
    "    \"\"\"\n",
    "    Update values with a given strategy\n",
    "    @TODO: values for `strategy`\n",
    "    `fill_value` only applies when strategy='constant'\n",
    "    {'constant', 'most_frequent', 'mean', 'median'}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        imputer = SimpleImputer(\n",
    "            missing_values=np.nan, strategy=strategy, fill_value=fill_value\n",
    "        )\n",
    "        imputer.fit(df[fields])\n",
    "        df_transformed = df.copy()\n",
    "        df_transformed[fields] = imputer.transform(df[fields])\n",
    "        return df_transformed\n",
    "    except ValueError as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1207,
   "id": "5ed6387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def encode_categorical_data(df, fields, encoder):\n",
    "    \"\"\"\n",
    "    Function to encode categorical data in a DataFrame:\n",
    "    - OneHot: tbd\n",
    "    - Dummy: tbd\n",
    "    - Label: tbd\n",
    "    @TODO: explain when applying each one\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if encoder == \"OneHot\":\n",
    "            # Create a ColumnTransformer, applying OneHotEncoder to specified fields\n",
    "            ct = ColumnTransformer(\n",
    "                transformers=[(\"encoder\", OneHotEncoder(), fields)],\n",
    "                remainder=\"passthrough\",\n",
    "            )\n",
    "            # Apply ColumnTransformer, resulting in an array\n",
    "            transformed_data = ct.fit_transform(df)\n",
    "            # Create new column names for the one-hot encoded columns\n",
    "            encoded_columns = ct.named_transformers_[\"encoder\"].get_feature_names_out(\n",
    "                fields\n",
    "            )\n",
    "            # Combine the new column names with the non-transformed columns\n",
    "            non_transformed_columns = [col for col in df.columns if col not in fields]\n",
    "            new_column_names = list(encoded_columns) + non_transformed_columns\n",
    "            # Create a DataFrame from the transformed data\n",
    "            df_transformed = pd.DataFrame(\n",
    "                transformed_data, columns=new_column_names, index=df.index\n",
    "            )\n",
    "\n",
    "        elif encoder == \"Dummy\":\n",
    "            # Create dummy variables\n",
    "            dummies = pd.get_dummies(df[fields], drop_first=True)\n",
    "            # Drop the original fields and concatenate the dummy variables\n",
    "            df_transformed = pd.concat([df.drop(fields, axis=1), dummies], axis=1)\n",
    "\n",
    "        elif encoder == \"Label\":\n",
    "            df_transformed = df.copy()\n",
    "            # update original target fields with 0-N categorical values\n",
    "            for field in fields:\n",
    "                le = LabelEncoder()\n",
    "                df_transformed[field] = le.fit_transform(df_transformed[field])\n",
    "        else:\n",
    "            print(f\"encoder `{encoder}` not found\")\n",
    "            return df\n",
    "\n",
    "        return df_transformed\n",
    "    except KeyError as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "id": "250d0ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "\n",
    "def scale_features(X_train, X_test, fields):\n",
    "    \"\"\"\n",
    "    - Only for non-dummy numerical features\n",
    "    - For KNN, SVM or Logistic Reg/Linear Reg/NN with Gradient descent optimisation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create copies of the original DataFrames\n",
    "        X_train_scaled, X_test_scaled = X_train.copy(), X_test.copy()\n",
    "\n",
    "        # Scale only the specified fields\n",
    "        X_train_scaled[fields] = sc.fit_transform(X_train[fields])\n",
    "        X_test_scaled[fields] = sc.transform(X_test[fields])\n",
    "\n",
    "        return X_train_scaled, X_test_scaled\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ef55dc",
   "metadata": {},
   "source": [
    "### Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "id": "543ca9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT FOR CLASSIFICATION! from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def fit_logistic_regression(X_train, y_train):\n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    lr.fit(X_train, y_train)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb160f5",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "id": "96f16ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch     Ticket     Fare Cabin Embarked  \n",
      "0        0  A/5 21171   7.2500   NaN        S  \n",
      "1        0   PC 17599  71.2833   C85        C  \n",
      "889      0     111369  30.0000  C148        C  \n",
      "890      0     370376   7.7500   NaN        Q  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../src/v1/07_scikit-learn/filez/titanic_train.csv')\n",
    "show_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9480465d",
   "metadata": {},
   "source": [
    "- field_1: description_1. Explanation.\n",
    "- field_2: description_2. Explanation.\n",
    "- field_3: description_3. Explanation.\n",
    "- field_4: description_4 (0 = No, 1 = Yes). Explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e37dc16",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "id": "ee3b3f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display DataFrame info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "id": "64500f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             # missing  % missing\n",
      "Cabin              687      77.10\n",
      "Age                177      19.87\n",
      "Embarked             2       0.22\n",
      "PassengerId          0       0.00\n",
      "Survived             0       0.00\n",
      "Pclass               0       0.00\n",
      "Name                 0       0.00\n",
      "Sex                  0       0.00\n",
      "SibSp                0       0.00\n",
      "Parch                0       0.00\n",
      "Ticket               0       0.00\n",
      "Fare                 0       0.00\n"
     ]
    }
   ],
   "source": [
    "# Display number and percentage of missing values\n",
    "show_missing_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "id": "37bd9c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 1213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe statistics on numerical fields\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "id": "ccd14e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex: ['male' 'female']\n",
      "Embarked: ['S' 'C' 'Q' nan]\n"
     ]
    }
   ],
   "source": [
    "# show unique values given a list of df fields\n",
    "show_unique_values(df, ['Sex', 'Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "id": "8ce26a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO: seaborn charts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da2900e",
   "metadata": {},
   "source": [
    "### Data cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27631d2c",
   "metadata": {},
   "source": [
    "    TO-BE-REMOVED\n",
    "- remove or update null values\n",
    "- manage outliers\n",
    "- drop irrelevant fields (i.e.: ids, names, ..)\n",
    "- correct data entry errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "id": "01bd099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update null values\n",
    "df = update_null_values(df=df, strategy='mean', fields=['Age'], fill_value=0)\n",
    "# Remove unnecessary fields\n",
    "df = df.drop([\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6c0e8f",
   "metadata": {},
   "source": [
    "### Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "id": "644e123d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  Embarked_Q  Embarked_S  \\\n",
       "0         0       3  22.0      1      0   7.2500       False        True   \n",
       "1         1       1  38.0      1      0  71.2833       False       False   \n",
       "\n",
       "   Sex_male  \n",
       "0      True  \n",
       "1     False  "
      ]
     },
     "execution_count": 1217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OneHot encoder - binary values / keep all values\n",
    "# df = encode_categorical_data(df=df, fields=['Embarked', 'Sex'], encoder='OneHot')\n",
    "# Dummy encoder - binary values / remove first value\n",
    "df = encode_categorical_data(df=df, fields=['Embarked', 'Sex'], encoder='Dummy')\n",
    "# Label encoder - integer values 0-N / keep all values\n",
    "# df = encode_categorical_data(df=df, fields=['Embarked', 'Sex'], encoder='Label')\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759ec0a",
   "metadata": {},
   "source": [
    "### Splitting dataset into Train/Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "id": "1ffab653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(\"Survived\", axis=1)\n",
    "y = df[\"Survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f21f0dd",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "id": "3baca652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "733    0\n",
       "857    1\n",
       "81     1\n",
       "319    1\n",
       "720    1\n",
       "      ..\n",
       "575    0\n",
       "838    1\n",
       "337    1\n",
       "523    1\n",
       "863    0\n",
       "Name: Survived, Length: 712, dtype: int64"
      ]
     },
     "execution_count": 1219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train_scaled, X_test_scaled = scale_features(\n",
    "#     X_train=X_train, X_test=X_test, fields=[\"Pclass\", \"Age\", \"SibSp\"]\n",
    "# )\n",
    "\n",
    "# X_train_scaled.head(2)\n",
    "y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea988e0",
   "metadata": {},
   "source": [
    "### Fit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "id": "a4f80ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = fit_logistic_regression(X_train=X_train, y_train=y_train)\n",
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a2e920",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "id": "d88377c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83        99\n",
      "           1       0.83      0.71      0.77        80\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.81      0.80      0.80       179\n",
      "weighted avg       0.81      0.80      0.80       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7b9292",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa7ecb58",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "149f8ed0",
   "metadata": {},
   "source": [
    "TODO: use new df's after every change, but beware of the mem space required.\n",
    "\n",
    "1. **Initial Stages**:\n",
    "   - `df_raw`: The original, unmodified dataset.\n",
    "   - `df_loaded`: Data after initial loading, possibly from multiple sources.\n",
    "\n",
    "2. **Cleaning and Preprocessing**:\n",
    "   - `df_cleaned`: After basic cleaning (removing duplicates, handling missing values).\n",
    "   - `df_filtered`: Data after filtering based on certain criteria.\n",
    "   - `df_imputed`: Where missing values have been imputed.\n",
    "   - `df_deduped`: After removing duplicates.\n",
    "\n",
    "3. **Feature Engineering**:\n",
    "   - `df_engineered`: After feature engineering (new features created).\n",
    "   - `df_transformed`: After applying transformations (log, square root, etc.).\n",
    "   - `df_normalized`: If the data has been normalized.\n",
    "   - `df_standardized`: If the data has been standardized.\n",
    "\n",
    "4. **Encoding and Formatting**:\n",
    "   - `df_encoded`: After encoding categorical variables (one-hot, label encoding).\n",
    "   - `df_binned`: After binning continuous variables.\n",
    "   - `df_pivoted`: If data has been pivoted or reshaped.\n",
    "   - `df_aggregated`: After aggregation operations (group by, etc.).\n",
    "\n",
    "5. **Splitting**:\n",
    "   - `df_train`: Training set.\n",
    "   - `df_test`: Test set.\n",
    "   - `df_validate`: Validation set.\n",
    "\n",
    "6. **Modeling**:\n",
    "   - `df_predictions`: Contains model predictions.\n",
    "   - `df_residuals`: Residuals from model predictions.\n",
    "   - `df_analyzed`: DataFrames used for deeper analysis post-modeling.\n",
    "\n",
    "7. **Results and Export**:\n",
    "   - `df_results`: Final results or outputs.\n",
    "   - `df_export`: Data ready to be exported to a file or database.\n",
    "\n",
    "8. **Special Cases**:\n",
    "   - `df_merged`: After merging with another DataFrame.\n",
    "   - `df_joined`: After joining with another DataFrame.\n",
    "   - `df_sampled`: If a sample has been taken from the data.\n",
    "   - `df_segmented`: If the data has been segmented (e.g., by customer type).\n",
    "\n",
    "Each name corresponds to a common data processing or analysis task and makes it easier to track the purpose of each DataFrame in your workflow. Remember, these are just examples, and the actual names should align with the specific operations and logic of your project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b60c6a9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
